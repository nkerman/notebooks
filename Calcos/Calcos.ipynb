{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topC\"></a>\n",
    "\n",
    "# Running the COS Pipeline (`calcos`)\n",
    "\n",
    "# Learning Goals\n",
    "### This Notebook is designed to walk the user (*you*) through:\n",
    "#### 1. **[Setting up the environment to run `calcos`](#setupC)**\n",
    "##### - 1.1. [Prerequisites](#prereqC)\n",
    "##### - 1.2. [Create your conda environment](#condaenvC)\n",
    "##### - 1.3. [Set up a reference file directory](#lrefC)\n",
    "\n",
    "\n",
    "#### 2. **[Processing raw COS data using `calcos`](#runC)**\n",
    "##### - 2.1. [Downloading the data](#datadlC)\n",
    "##### - 2.2. [Gathering reference files](#reffileC)\n",
    "##### - 2.3. [Running `calcos`: *From a python environment*](#runpyC)\n",
    "##### - 2.4. [Running `calcos`: *From the command line*](#runcliC)\n",
    "\n",
    "\n",
    "#### 3. **[Re-processing data COS data with altered parameters](#rerunC)**\n",
    "##### - 3.1. [Altering the calibration switches](#alterswitchC)\n",
    "##### - 3.2. [Running `calcos` with a specific set of switches](#switchrunC)\n",
    "##### - 3.3. [Running `calcos` with a different reference file](#refrunC)\n",
    "\n",
    "\n",
    "\n",
    "# 0. Introduction\n",
    "#### The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).\n",
    "\n",
    "#### **`Calcos`** is the data processing pipeline which converts the raw data produced by COS's detectors onboard Hubble into usable spectral data. It transitions the data from a list of many individual recorded photon interactions into tables of wavelength and flux.\n",
    "#### This tutorial aims to prepare you run the `calcos` pipeline to reduce spectral data taken with the COS instrument. It focuses on COS data taken in `TIME-TAG` mode.\n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes for those new to Python/Jupyter/Coding:\n",
    "- You will frequently see exclamation points (**!**) or dollar signs (**\\$**) at the beginning of a line of code. These are not part of the actual commands. The exclamation points tell a jupyter notebook to pass the following line to the command line, and the dollar sign merely indicates the start of a terminal prompt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- `astroquery.mast Mast and Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `numpy` to handle array functions (version $\\ge$ 1.17)\n",
    "- `astropy.io` fits for accessing FITS files\n",
    "- `astropy.table Table` for creating tidy tables of the data\n",
    "<!-- - `astropy.units` and `astropy.visualization.quantity_support` for dealing with units -->\n",
    "- `matplotlib.pyplot` for plotting data\n",
    "- `glob` and `os` for searching and working with system files\n",
    "\n",
    "- *Later on, we will import the `calcos` package to run out pipeline*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This line is just to make any plots we might make look good in a notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Manipulating arrays\n",
    "import numpy as np\n",
    "\n",
    "# Reading in data\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Downloading data from archive\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "# Searching for files on our system\n",
    "import glob\n",
    "# Making directories and such\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will also define a few directories in which to place our data and plots, as well as a few colors we will use in plots later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be important directories for the notebook\n",
    "cwd = !pwd\n",
    "cwd = cwd[0]\n",
    "\n",
    "!mkdir ./data\n",
    "!mkdir ./output/\n",
    "\n",
    "datadir = cwd + '/data/'\n",
    "outputdir = cwd + '/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = setupC></a>\n",
    "# 1. Setting up the environment to run calcos\n",
    "\n",
    "The first step to processing your data is setting up an environment from which to run `calcos`.\n",
    "<a id = prereqC></a>\n",
    "## 1.1. Prerequisites\n",
    "This tutorial assumes some basic knowledge of the command line and was built using a unix bash-style shell. Those using a Windows computer will likely have the best results if working within the [Windows Subsystem for Linux](https://docs.microsoft.com/en-us/windows/wsl/install-win10).\n",
    "\n",
    "\n",
    "If you do not already have any distribution of the `conda` tool, see [this page](https://astroconda.readthedocs.io/en/latest/getting_started.html#getting-started-jump) for instructions, and install either [`anaconda` - more beginner friendly, \\~ 3 GB, lots of extras you likely won't use](https://docs.anaconda.com/anaconda/install/) or [`miniconda` - \\~ 400 MB, only what you need](https://docs.conda.io/en/latest/miniconda.html).\n",
    "\n",
    "<a id = condaenvC></a>\n",
    "## 1.2. Create your conda environment\n",
    "Once you have `conda` installed, it's time to create an environment. If you already setup an `astroconda` environment in the notebook on \"Setting up your environment\", you may skip this and merely activate the environment you created then.\n",
    "\n",
    "Open up your terminal app, likely `Terminal` or `iTerm` on a Mac or `Windows Terminal` or `Powershell` on Windows.\n",
    "\n",
    "First, add the stsci channel to your computer's conda channel list. This enables conda to look in the right place to find all the packages we want to install.\n",
    "\n",
    "\n",
    "``` $ conda config --add channels http://ssb.stsci.edu/astroconda```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new environment for running calcos; let's call it `calcos_env`, and initialize it with the packages in the stsci channel's list we just added.\n",
    "\n",
    "\n",
    "``` $ conda create -n calcos_env stsci ```\n",
    "\n",
    "After allowing conda to proceed to installing the packages (type `y` then hit enter/return), you can see all of your environments with:\n",
    "\n",
    "``` $ conda env list```\n",
    "\n",
    "and then switch over to your new environment with \n",
    "\n",
    "``` $ conda activate calcos_env ```\n",
    "\n",
    "At this point, typing `calcos` into the command line and hitting enter should no longer yield the error \n",
    "\n",
    "> ```command not found: calcos``` \n",
    "\n",
    "but rather respond that:\n",
    "\n",
    "> ```The command-line options are:\n",
    "  --version (print the version number and exit)\n",
    "  -r (print the full version string and exit)\n",
    "  ...\n",
    "  ERROR:  An association file name or observation rootname must be specified.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = lrefC></a>\n",
    "## 1.3. Set up a reference file directory\n",
    "\n",
    "`calcos` needs to be able to find all your reference files, (flat field image, bad pixel table, etc.), and the best way to enable that is to create a central directory of all the calibration files you'll need. We refer to this directory  as \"lref\" by convention, and set a system variable `lref` to the location of the directory. \n",
    "\n",
    "We can assign a system variable in three different ways, depending on whether we are working from:\n",
    "1. The command line\n",
    "2. A python environment\n",
    "3. A Jupyter Notebook\n",
    "\n",
    "|Unix-style Command Line| Python | Jupyter Notebook|\n",
    "|-|-|-|\n",
    "| export lref='./data/reference' | import os| %env lref ./data/reference|\n",
    "||os.environ[\"lref\"] = \"./data/reference\" ||\n",
    "\n",
    "\n",
    "Note that this system variable must be set again with every new instance of a terminal - if you frequently need to use the same `lref` directory, consider adding an export statement to your `.bash_profile` or equivalent file.\n",
    "\n",
    "Because this is a jupyter notebook, we set our reference directory with the [cell magic](https://ipython.readthedocs.io/en/stable/interactive/magics.html) below:\n",
    "\n",
    "<!-- Looking in the headers of our data below, we see that the `$lref` argument appears at the beginning of all of the reference file locations: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env lref ./data/reference/references/hst/cos/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note the value of the system variable using the `echo` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo $lref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can create the directory with the line below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = runC></a>\n",
    "# 2. Processing raw COS data using `calcos`\n",
    "\n",
    "The calcos pipeline can be run either from a python environment, or directly from a Unix-style command line. The two use the same underlying machinery but can differ in syntax. For specifics on the keywords to run `calcos` with specific behaviors and arguments, see [Table 3.2: Arguments for Running calcos in Python](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration) and [Table 3.2:Command-line Options for Running calcos in Unix/Linux/Mac](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration).\n",
    "\n",
    "<a id = datadlC></a>\n",
    "## 2.1. Downloading the data\n",
    "\n",
    "First, we need to make sure we have all of our data ready and in the right spot. If you are unfamiliar with searching the archive for data, we recommend that you view our [tutorial on downloading COS data](https://github.com/spacetelescope/COS-Notebooks). This notebook will largely gloss over downloading the data.\n",
    "\n",
    "To run calcos, we will need the following files:\n",
    "1. All the **raw data** from separate exposures we wish to combine as `rawtag` fits files\n",
    "2. The **association** file telling calcos which files to combine as a `asn` fits file.\n",
    "\n",
    "For this example, we're choosing the dataset `LCXV13040` of COS/FUV observing the [quasar 3C48](https://en.wikipedia.org/wiki/3C_48). In the cell below we download the data from the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the MAST archive for data with observation id starting with lcxv1304\n",
    "q1 = Observations.query_criteria(obs_id = 'lcxv1304*')\n",
    "\n",
    "# Get a list of all products we could download associates with this file\n",
    "pl = Observations.get_product_list(q1)\n",
    "\n",
    "# Get a list of only the products which are association files\n",
    "asn_file_list = pl[pl[\"productSubGroupDescription\"] == 'ASN']\n",
    "\n",
    "# Get a list of only the products which are rawtag files\n",
    "rawtag_list = pl[(pl[\"productSubGroupDescription\"] == 'RAWTAG_A') | (pl[\"productSubGroupDescription\"] == 'RAWTAG_B')]\n",
    "\n",
    "#Download the two lists to the data directory\n",
    "Observations.download_products(rawtag_list, download_dir='./data')\n",
    "Observations.download_products(asn_file_list, download_dir='./data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, each exposure's files are downloaded to separate directories, as is the association file.\n",
    "We need to move around these files to all be in the same directory, which we do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./data/mastDownload/HST/lcxv13*/*fits* ./data\n",
    "!rm -r ./data/mastDownload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = reffileC></a>\n",
    "## 2.2. Gathering reference files\n",
    "\n",
    "Each data file has an associated set of calibration files which are needed to run the associated correction with (i.e. you need the `FLATFILE` to flat field correct the data.) These reference files must be located in the `$lref` directory to run the pipeline.\n",
    "\n",
    "The Space Telescope Science Institute (STScI) team is regularly producing new calibration files, in an effort to keep improving data reduction. Periodically the pipeline is re-run on all COS data.\n",
    "To determine which reference files were used most recently by STScI to calibrate your data (often, but not always the newest/best,) you can refer to your data file's \"CRDS_CTX\" keyword in its fits header (see next cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfiles = glob.glob('data/*raw*.fits')\n",
    "crds_ctx = fits.getheader(rawfiles[0])['CRDS_CTX']\n",
    "print(f\"The CRDS Context last run with {rawfiles[0]} was:\\t{crds_ctx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of this keyword in the header is a `.pmap` file which tells the CRDS calibration data distribution program which files to distribute. To download the reference files specified by the context, we use the tool `crds`, installed with the stsci conda channel. \n",
    "\n",
    "Again, we first need to set some system variables to tell the program where to look and save the downloaded files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= ./figures/warning.png width =\"60\" title=\"CAUTION!\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that as of the time of this notebook's creation, the context used below was **`hst_0836.pmap`**. You are running this in the future, and there is very possibly a newer context you would be better off working with. Take a minute to consider this, and check the results of the previous code cell before running the next cell.\n",
    "\n",
    "Also note that this cell can produce quite a lot of output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n",
    "%env CRDS_PATH ./data/reference/\n",
    "\n",
    "# The next line depends on your context and pmap file \n",
    "!crds bestrefs --files data/*raw*.fits  --sync-references=2 --update-bestrefs --new-context 'hst_0836.pmap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir+'crds_output_1.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can run the pipeline on our data using our reference files\n",
    "\n",
    "This following cell running the pipeline can take several minutes, sometimes more than **10 minutes**, so you do *not* need to run this cell. It also outputs hundreds of lines of text if the verbosity parameter is set to 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = runpyC></a>\n",
    "## 2.3. Running `calcos`: *From a python environment*\n",
    "\n",
    "First, we import the pipeline package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calcos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we can run the pipeline program!\n",
    "\n",
    "Note that generally, calcos should be run on an association file (in this case: `./data/lcxv13040_asn.fits`). In this case we also specify that `verbosity` = 2, resulting in a **very** verbose output, and we specify a directory to put all the output files in: `output/calcos_processed_1`. To avoid polluting this notebook with more than a thousand lines of the output, we capture the output of the next cell and save it to `output/output_calcos_1.txt` in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "calcos.calcos('./data/lcxv13040_asn.fits', verbosity=2, outdir=outputdir+\"/calcos_processed_1\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir+'output_calcos_1.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = runcliC></a>\n",
    "\n",
    "## 2.4. Running `calcos`: *From the command line*\n",
    "\n",
    "The syntax for running calcos from the command line is very similar. Assuming your data files, `lref` directory, and reference files are all in order, you can simply run:\n",
    "\n",
    "```calcos --outdir directory_to_save_outputs_in filename_asn.fits```\n",
    "\n",
    "*or, if you want to save a very verbose output to a log file `log.txt`*:\n",
    "\n",
    "```calcos -v --outdir directory_to_save_outputs_in filename_asn.fits > log.txt```\n",
    "\n",
    "To see the full list of commands, [Table 3.2:Command-line Options for Running calcos in Unix/Linux/Mac](https://hst-docs.stsci.edu/cosdhb/chapter-3-cos-calibration/3-6-customizing-cos-data-calibration), or run the following cell with no arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!calcos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = rerunC></a>\n",
    "# 3. Re-processing data COS data with altered parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = alterswitchC></a>\n",
    "## 3.1. Altering the calibration switches\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to tweak how `calcos` runs - which calibrations it performs - is with the calibration switches contained in the fits headers. The switches (with the exception of \"XTRACTALG\"), can be set to:\n",
    "\n",
    "|\"PERFORM\"|\"OMIT\"|\"N/A\"|\n",
    "|-|-|-|\n",
    "|Performs the calibration step|Does not perform the calibration step|This step would not make sense for this file|\n",
    "\n",
    "In the cell below, we get a full list of the switches by name. If you to learn more about the calibration steps and switches, see [Chapters 2 and 3 of the COS Data Handbook](https://hst-docs.stsci.edu/cosdhb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = fits.getheader(rawfiles[0])\n",
    "calibswitches = header[82:109]\n",
    "calibswitches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's begin by switching off all the switches currently set to \"PERFORM\" to a new value of \"OMIT\", in every rawfile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False \n",
    "\n",
    "for i, rawfile in enumerate(rawfiles):\n",
    "    if verbose:\n",
    "        print(rawfile)\n",
    "    header = fits.getheader(rawfiles[i])\n",
    "    corrections = [key for key in list(header.keys()) if \"CORR\" in key]\n",
    "\n",
    "    for correction in corrections:\n",
    "        if header[correction] == 'PERFORM':\n",
    "            if verbose:\n",
    "                print(\"switching\\t\", header[correction], \"\\t\",correction, \"\\tto OMIT\")\n",
    "            fits.setval(rawfile, correction, value='OMIT', ext = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `calcos` realizes that all the switches are set to \"OMIT\", and exits without doing anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calcos.calcos('./data/lcxv13040_asn.fits', verbosity=0, outdir=outputdir+\"calcos_processed_2\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = switchrunC></a>\n",
    "## 3.2. Running `calcos` with a specific set of switches\n",
    "Now, let's set a single switch to \"PERFORM\", and just run a flat-field correction (\"FLATCORR\") and a pulse-height filter correction (\"PHACORR\"). Set verbosity = 1 or 2 to learn more about how calcos is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "\n",
    "for i, rawfile in enumerate(rawfiles):\n",
    "    if verbose:\n",
    "        print(rawfile)\n",
    "    fits.setval(rawfile, \"FLATCORR\", value='PERFORM', ext = 0)\n",
    "    fits.setval(rawfile, \"PHACORR\", value='PERFORM', ext = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "calcos.calcos('./data/lcxv13040_asn.fits', verbosity=2, outdir=outputdir+\"calcos_processed_3\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir+'output_calcos_3.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = refrunC></a>\n",
    "## 3.3. Running `calcos` with a different reference file\n",
    "\n",
    "You may wish to run `calcos` with a specific flat file, bad pixel table, or any other reference file. `calcos` offers the ability to do just this on a file-by-file basis, by changing the CALIBRATION REFERENCE FILES values in the header of your data.\n",
    "\n",
    "As an example, we check which calibration files are selected for one of our rawtag files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = fits.getheader(rawfiles[0])\n",
    "refFiles = header[110:138]\n",
    "refFile_keys = list(refFiles[2:].keys())\n",
    "refFiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's download another Pulse Height Amplitude (\\_pha) table file using the `crds` tool (*I picked this one at random*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!crds sync --files u1t1616ll_pha.fits --output-dir $lref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we can use the fits headers to set this new file as the `_pha` file. Let's do this for **only** the raw data from segment FUVA of the FUV detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfiles_segA = glob.glob('data/*rawtag_a*.fits')\n",
    "for rawfileA in rawfiles_segA:\n",
    "    print(rawfileA)\n",
    "    with fits.open(rawfileA, mode = 'update') as hdulist:\n",
    "        hdr0 = hdulist[0].header\n",
    "        hdr0[\"PHATAB\"] = 'lref$u1t1616ll_pha.fits' #NOTE that you need the lref$ in there if you put it with your other ref files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, let's run `calcos` with the new `_pha` file for only the FUVA data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "calcos.calcos('./data/lcxv13040_asn.fits', verbosity=2, outdir=outputdir+\"/calcos_processed_4\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir+'output_calcos_4.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we go, let's have a look at the spectra we calibrated and extracted in part [2.3](#runpyC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's make a quick plot to show the spectra calibrated by STScI's pipeline and by us right now: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.download_products(Observations.get_product_list(Observations.query_criteria(obs_id = 'lcxv13040')), mrp_only=True,  download_dir = 'data/compare/')\n",
    "\n",
    "output_spectrum = Table.read('./data/compare/mastDownload/HST/lcxv13040/lcxv13040_x1dsum.fits')\n",
    "wvln_orig, flux_orig, fluxErr_orig, dqwgt_orig = output_spectrum[1][\"WAVELENGTH\", \"FLUX\", \"ERROR\" ,\"DQ_WGT\"]\n",
    "dqwgt_orig = np.asarray(dqwgt_orig, dtype=bool)\n",
    "\n",
    "output_spectrum = Table.read('output/calcos_processed_1/lcxv13040_x1dsum.fits')\n",
    "new_wvln, new_flux, new_fluxErr, new_dqwgt = output_spectrum[1][\"WAVELENGTH\", \"FLUX\", \"ERROR\" ,\"DQ_WGT\"]\n",
    "new_dqwgt = np.asarray(new_dqwgt, dtype=bool)\n",
    "\n",
    "fig, (ax0,ax1, ax2) = plt.subplots(3,1,figsize=(20,20))\n",
    "ax0.plot(wvln_orig[dqwgt_orig], flux_orig[dqwgt_orig], linewidth = 0.5, label = \"Processed by the archive\")\n",
    "ax1.plot(new_wvln[new_dqwgt], new_flux[new_dqwgt], linewidth = 0.5, label = \"Just now processed by you\")\n",
    "\n",
    "ax2.plot(wvln_orig[dqwgt_orig], flux_orig[dqwgt_orig], linewidth = 0.5, label = \"Processed by the archive\")\n",
    "ax2.plot(new_wvln[new_dqwgt], new_flux[new_dqwgt], linewidth = 0.5, label = \"Just now processed by you\")\n",
    "ax0.legend(loc = 'upper center',fontsize = 14);ax1.legend(loc = 'upper center',fontsize = 14); ax2.legend(loc = 'upper center',fontsize = 14)\n",
    "ax0.set_title(\"Comparison of processed spectra\",size = 28)\n",
    "plt.tight_layout()\n",
    "plt.savefig(outputdir + \"compare_plot.png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this notebook!\n",
    "### There are more COS data walkthrough notebooks on different topics. You can find them [here](https://github.com/spacetelescope/COS-Notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this Notebook\n",
    "**Author:** [Nat Kerman](nkerman@stsci.edu)\n",
    "\n",
    "**Updated On:** 2020-11-02\n",
    "\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`/`numpy`/`matplotlib`](https://www.scipy.org/citing.html)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#topV)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
