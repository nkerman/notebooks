{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough schema\n",
    "\n",
    "1. Editing existing asn file\n",
    "    - 1.1. Removing an exposure\n",
    "    - 1.2. Adding an exposure\n",
    "2. Creating an entirely new asn file\n",
    "3. ~~Optionally reproccesing the data~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"topAF\"></a>\n",
    "\n",
    "# Modifying an Association File\n",
    "\n",
    "# Learning Goals\n",
    "### This Notebook is designed to walk the user (*you*) through: **Altering the association (`asn`) file used by the Cosmic Origins Spectrograph (*COS*) pipeline to determine which data to process**:\n",
    "   #### 1. [**Examining an association file**](#examAF)\n",
    "   #### 2. [**Editing an existing association file**](#editAF)\n",
    "   ##### - 2.1. [Removing an exposure](#subAF)\n",
    "   ##### - 2.2. [Adding an exposure](#addAF)\n",
    "   #### 3. [**Creating an entirely new association file**](#newAF)\n",
    "   ##### - 3.1. [Simplest method](#simpleAF)\n",
    "   ##### - 3.2. [With fits header metadata](#metaAF)\n",
    "<!--    #### 3. [**Reprocessing the data**](#calcosAF) **Optional** -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction\n",
    "#### The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope ([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*). \n",
    "\n",
    "#### This tutorial aims to prepare you to alter the association file used by the `calcos` pipeline. \n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n",
    "\n",
    "We'll demonstrate creating an `asn` file in two ways:\n",
    "1. Editing an existing `asn` file to add or remove an exposure\n",
    "2. Creating an entirely new `asn` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- numpy to handle array functions\n",
    "- astropy.io fits and astropy.table Table for accessing FITS files\n",
    "- glob, os, and shutil for working with system files\n",
    "- astroquery.mast Mast and Observations for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- datetime for updating fits headers with today's date\n",
    "\n",
    "These python packages are installed standard with the the STScI conda distribution. For more information, see our notebook tutorial on [setting up an environment](https://github.com/spacetelescope/COS-Notebooks/blob/master/Setup/Setup.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for array manipulation\n",
    "import numpy as np\n",
    "# for reading fits files\n",
    "from astropy.io import fits                                            \n",
    "from astropy.table import Table\n",
    "# for system files\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "# for downloading the data\n",
    "from astroquery.mast import Observations\n",
    "# for changing today's date in a fits header\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will also define a few directories we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'\n",
    "output_dir = './output/'\n",
    "plots_dir = output_dir + 'plots/'\n",
    "# Make the directories in case they don't exist\n",
    "!mkdir ./data\n",
    "!mkdir ./output \n",
    "!mkdir ./output/plots/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And we will need to download the data we wish to filter and analyze\n",
    "We choose the exposures with the association obs_ids: `ldif01010` and `ldif02010` because we know that some of the exposures in these groups failed. For more information on downloading COS data, see our [notebook tutorial on downloading COS data](https://github.com/spacetelescope/COS-Notebooks/blob/master/DataDL/DataDl.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01010_asn.fits to ./data/mastDownload/HST/ldif01010/ldif01010_asn.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01tyq_rawtag_a.fits to ./data/mastDownload/HST/ldif01tyq/ldif01tyq_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01tyq_rawtag_b.fits to ./data/mastDownload/HST/ldif01tyq/ldif01tyq_rawtag_b.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u0q_rawtag_a.fits to ./data/mastDownload/HST/ldif01u0q/ldif01u0q_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u0q_rawtag_b.fits to ./data/mastDownload/HST/ldif01u0q/ldif01u0q_rawtag_b.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u2q_rawtag_a.fits to ./data/mastDownload/HST/ldif01u2q/ldif01u2q_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u2q_rawtag_b.fits to ./data/mastDownload/HST/ldif01u2q/ldif01u2q_rawtag_b.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u4q_rawtag_a.fits to ./data/mastDownload/HST/ldif01u4q/ldif01u4q_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif01u4q_rawtag_b.fits to ./data/mastDownload/HST/ldif01u4q/ldif01u4q_rawtag_b.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02010_asn.fits to ./data/mastDownload/HST/ldif02010/ldif02010_asn.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nmq_rawtag_a.fits to ./data/mastDownload/HST/ldif02nmq/ldif02nmq_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nmq_rawtag_b.fits to ./data/mastDownload/HST/ldif02nmq/ldif02nmq_rawtag_b.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nsq_rawtag_a.fits to ./data/mastDownload/HST/ldif02nsq/ldif02nsq_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nsq_rawtag_b.fits to ./data/mastDownload/HST/ldif02nsq/ldif02nsq_rawtag_b.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nuq_rawtag_a.fits to ./data/mastDownload/HST/ldif02nuq/ldif02nuq_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nuq_rawtag_b.fits to ./data/mastDownload/HST/ldif02nuq/ldif02nuq_rawtag_b.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nwq_rawtag_a.fits to ./data/mastDownload/HST/ldif02nwq/ldif02nwq_rawtag_a.fits ... [Done]\n",
      "Downloading URL https://mast.stsci.edu/api/v0.1/Download/file?uri=mast:HST/product/ldif02nwq_rawtag_b.fits to ./data/mastDownload/HST/ldif02nwq/ldif02nwq_rawtag_b.fits ... [Done]\n"
     ]
    }
   ],
   "source": [
    "pl = Observations.get_product_list(Observations.query_criteria(obs_id = 'ldif0*10')) # search for the correct obs_ids and get the product list \n",
    "arr = []\n",
    "[arr.append(i) for i, psg in enumerate(pl['productSubGroupDescription']) if psg in ['RAWTAG_A', 'RAWTAG_B','ASN']] # get the indices of rawtag and asn files in the product list\n",
    "Observations.download_products(pl[arr], download_dir = './data/') # Download these chosen products\n",
    "for gfile in glob.glob(\"**/ldif*/*.fits\", recursive=True): # Move all fits files in this set to the base data directory\n",
    "    os.rename(gfile,data_dir + os.path.basename(gfile))\n",
    "shutil.rmtree(data_dir + 'mastDownload') # Delete the empty nested mastDownload directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = examAF></a>\n",
    "# 1. Examining an association file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we downloaded two association files and their rawtag data files. We will begin by searching for the association files and reading one of them (`LDIF01010`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table140305580426856\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        1\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asnfiles = glob.glob(\"**/*ldif*asn*\", recursive=True) # There will be two (ldif01010_asn.fits and ldif02010_asn.fits)\n",
    "asnfile = asnfiles[0] # We want to work primarily with ldif01010_asn.fits\n",
    "asn_contents = Table.read(asnfile) # Gets the contents of the asn file\n",
    "asn_contents # Display these contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the association file has five rows: four exposures denoted with the `MEMTYPE` = `EXP-FP`, and a product with `MEMTYPE` = `PROD-FP`.\n",
    "\n",
    "In the cell below, we examine a bit about each of the exposures as a diagnostic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association LDIF01010 has EXP-FP exposure LDIF01TYQ with exptime 0.0 seconds at cenwave 1280 Å and FP-POS 1.\n",
      "Association LDIF01010 has EXP-FP exposure LDIF01U0Q with exptime 1404.0 seconds at cenwave 1280 Å and FP-POS 2.\n",
      "Association LDIF01010 has EXP-FP exposure LDIF01U2Q with exptime 1404.0 seconds at cenwave 1280 Å and FP-POS 3.\n",
      "Association LDIF01010 has EXP-FP exposure LDIF01U4Q with exptime 2923.0 seconds at cenwave 1280 Å and FP-POS 4.\n"
     ]
    }
   ],
   "source": [
    "for memname, memtype in zip(asn_contents['MEMNAME'], asn_contents[\"MEMTYPE\"]): #looks through each file in asn table\n",
    "    memname = memname.lower() # get file names in lower case letters\n",
    "    if memtype == 'EXP-FP': # We only want to look at the exposure files\n",
    "        rt_a = (glob.glob(f\"**/*{memname}*rawtag_a*\", recursive=True))[0] # Get the actual filepath of the memname for rawtag_a and rawtag_b\n",
    "        rt_b = (glob.glob(f\"**/*{memname}*rawtag_b*\", recursive=True))[0]\n",
    "        # Now print all these diagnostics:\n",
    "        print(f\"Association {(fits.getheader(rt_a))['ASN_ID']} has {memtype} exposure {memname.upper()} with \\\n",
    "exptime {(fits.getheader(rt_a, ext = 1))['EXPTIME']} seconds at cenwave {(fits.getheader(rt_a, ext = 0))['CENWAVE']} Å and FP-POS {(fits.getheader(rt_a, ext = 0))['FPPOS']}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Something seems amiss with exposure LDIF01TYQ!\n",
    "This file has an exposure time of 0.0 seconds - something has gone wrong. In this case, there was a guide star acquisition failure as described on the [data preview page](http://archive.stsci.edu/cgi-bin/mastpreview?mission=hst&dataid=LDIF01010).\n",
    "\n",
    "In the next section, we will work to correct this lack of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = editAF></a>\n",
    "# 2. Editing an existing association file\n",
    "\n",
    "<a id = subAF></a>\n",
    "## 2.1. Removing an exposure\n",
    "\n",
    "We know that at least one of our exposures - `ldif01tyq` - is not suited for combination into the final product. It has an exposure time of 0.0 seconds, in this case from a guide star acquisition failure. This is a generalizable issue, as you may often know an exposure is \"*bad*\" for many reasons: perhaps they were taken with the shutter closed, or with anomolously high background noise, or any number of reasons we may wish to exclude them from our data. To do this, we will need to alter our existing association file before we re-run `calcos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again see the contents of our main association file below. Note that `True/False` and `1/0` are essentially interchangable in the `MEMPRSNT` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table140305580699832\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        1\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(asnfiles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can set the `MEMPRSNT` value to `False` or `0` for our bad exposure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table140305580428312\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>0</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        0\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with fits.open(asnfile, mode = 'update') as hdulist: # We need to change things with the asnfile opened and in 'update' mode\n",
    "    tbdata = hdulist[1].data # This is where the table data is\n",
    "    for expfile in tbdata: # Check if each file is one of the bad ones\n",
    "        if expfile['MEMNAME'] in ['LDIF01TYQ']:\n",
    "            expfile['MEMPRSNT'] = False # If so, set MEMPRSNT to False AKA 0\n",
    "Table.read(asnfile) # Re-read the table to see the change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = addAF></a>\n",
    "## 2.2. Adding an exposure\n",
    "We removed the failed exposure taken with `FP-POS = 1`. Usually we want to combine one of each of the four [*fixed-pattern noise positions* (`FP-POS`)](https://hst-docs.stsci.edu/cosdhb/chapter-1-cos-overview/1-1-instrument-capabilities-and-design), so lets add the `FP-POS = 1` exposure from the other association group.\n",
    "\n",
    "In the cell below, we determine which exposure this is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association LDIF02010 has EXP-FP exposure LDIF02NMQ with exptime 1653.0 seconds at cenwave 1280 Å and FP-POS 1.\n",
      "^^^ The one above this has the right FP-POS! (LDIF02NMQ)^^^\n",
      "Association LDIF02010 has EXP-FP exposure LDIF02NSQ with exptime 1334.0 seconds at cenwave 1280 Å and FP-POS 2.\n",
      "Association LDIF02010 has EXP-FP exposure LDIF02NUQ with exptime 1334.0 seconds at cenwave 1280 Å and FP-POS 3.\n",
      "Association LDIF02010 has EXP-FP exposure LDIF02NWQ with exptime 2783.0 seconds at cenwave 1280 Å and FP-POS 4.\n"
     ]
    }
   ],
   "source": [
    "asn_contents_2 = Table.read(asnfiles[1]) # Gets the contents of the SECOND asn file\n",
    "\n",
    "for memname, memtype in zip(asn_contents_2['MEMNAME'], asn_contents_2[\"MEMTYPE\"]): #looks through each file in asn table\n",
    "    memname = memname.lower() # get file names in lower case letters\n",
    "    if memtype == 'EXP-FP': # We only want to look at the exposure files\n",
    "        rt_a = (glob.glob(f\"**/*{memname}*rawtag_a*\", recursive=True))[0] # Get the actual filepath of the memname for rawtag_a and rawtag_b\n",
    "        rt_b = (glob.glob(f\"**/*{memname}*rawtag_b*\", recursive=True))[0]\n",
    "        # Now print all these diagnostics:\n",
    "        print(f\"Association {(fits.getheader(rt_a))['ASN_ID']} has {memtype} exposure {memname.upper()} with \\\n",
    "exptime {(fits.getheader(rt_a, ext = 1))['EXPTIME']} seconds at cenwave {(fits.getheader(rt_a, ext = 0))['CENWAVE']} Å and FP-POS {(fits.getheader(rt_a, ext = 0))['FPPOS']}.\")\n",
    "\n",
    "        if (fits.getheader(rt_a, ext = 0))['FPPOS'] == 1:\n",
    "            print(f\"^^^ The one above this has the right FP-POS! ({memname.upper()})^^^\")\n",
    "            asn2_fppos1_name = memname.upper() # save the right file basename to a variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a slightly different procedure to add a new exposure to the list rather than remove one. \n",
    "\n",
    "Here we want to read the table in the fits association file into an `astropy` Table. We can then add a row into the right spot, filling it with the new file's `MEMNAME`, `MEMTYPE`, and `MEMPRSNT`. Finally, we have to save this table into the existing fits association file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_orig_table = Table.read(asnfile) # Read in original data from the file\n",
    "asn_orig_table.insert_row(len(asn_orig_table)- 1 , [asn2_fppos1_name,'EXP-FP',1]) # add a row with the right name after all the original EXP-FP's\n",
    "new_table = fits.BinTableHDU(asn_orig_table)\n",
    "\n",
    "with fits.open(asnfile, mode = 'update') as hdulist: # We need to change things with the asnfile opened and in 'update' mode\n",
    "    hdulist[1].data = new_table.data  # Change the orig file's data to the new table data we made"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see there is a new row with our exposure from the other `asn` file group: `LDIF02NWQ`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=6</i>\n",
       "<table id=\"table140305580877864\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes14</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF01TYQ</td><td>EXP-FP</td><td>0</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U2Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF02NMQ</td><td>EXP-FP</td><td>1</td></tr>\n",
       "<tr><td>LDIF01010</td><td>PROD-FP</td><td>1</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=6>\n",
       "   MEMNAME        MEMTYPE     MEMPRSNT\n",
       "   bytes14        bytes14       bool  \n",
       "-------------- -------------- --------\n",
       "     LDIF01TYQ         EXP-FP        0\n",
       "     LDIF01U0Q         EXP-FP        1\n",
       "     LDIF01U2Q         EXP-FP        1\n",
       "     LDIF01U4Q         EXP-FP        1\n",
       "     LDIF02NMQ         EXP-FP        1\n",
       "     LDIF01010        PROD-FP        1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excellent! In the next section we will create a new association file from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = newAF></a>\n",
    "# 3. Creating an entirely new association file\n",
    "\n",
    "For the sake of demonstration, we will generate a new association file with four exposure members: even-numbered `FP-POS` (2,4) from the first original association (`LDIF01010`), and odd-numbered `FP-POS` (1,3) from from the second original association (`LDIF02010`).\n",
    "\n",
    "From section 2, we see that this corresponds to :\n",
    "\n",
    "|Name|Original asn|FP-POS|\n",
    "|----|------------|------|\n",
    "|LDIF02010|LDIF02NMQ|1|\n",
    "|LDIF01010|LDIF01U0Q|2|\n",
    "|LDIF02010|LDIF02NUQ|3|\n",
    "|LDIF01010|LDIF01U4Q|4|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = simpleAF></a>\n",
    "## 3.1. Simplest method\n",
    "Below, we manually build up an association file from the three necessary columns:\n",
    "1. `MEMNAME`\n",
    "2. `MEMTYPE`\n",
    "3. `MEMPRSNT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ldifcombo_asn.fitsin the output directory: ./output/\n"
     ]
    }
   ],
   "source": [
    "# Adding the exposure file details to the association table\n",
    "new_asn_memnames = ['LDIF02NMQ','LDIF01U0Q','LDIF02NUQ','LDIF01U4Q'] # MEMNAME\n",
    "types = ['EXP-FP', 'EXP-FP', 'EXP-FP', 'EXP-FP'] # MEMTYPE\n",
    "included = [True, True, True, True] # MEMPRSNT\n",
    "\n",
    "# Adding the ASN details to the end of the association table\n",
    "new_asn_memnames.append('ldifcombo'.upper()) # MEMNAME\n",
    "types.append('PROD-FP') # MEMTYPE\n",
    "included.append(True) # MEMPRSNT\n",
    "\n",
    "# Putting together the fits table\n",
    "#   40 is the number of characters allowed in this field. If your rootname is longer than 40, \n",
    "#     you will need to increase this\n",
    "c1 = fits.Column(name='MEMNAME', array=np.array(new_asn_memnames), format='40A') \n",
    "c2 = fits.Column(name='MEMTYPE', array=np.array(types), format='14A')\n",
    "c3 = fits.Column(name='MEMPRSNT', format='L', array=included)\n",
    "asn_table = fits.BinTableHDU.from_columns([c1, c2, c3])\n",
    "\n",
    "# Writing the fits table\n",
    "asn_table.writeto(output_dir + 'ldifcombo_asn.fits', overwrite = True)\n",
    "\n",
    "print('Saved: '+ 'ldifcombo_asn.fits'+ f\"in the output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the file we have created:\n",
    "##### We see that the data looks great - exactly the table we want!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table140305580428648\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes40</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF02NMQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF02NUQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIFCOMBO</td><td>PROD-FP</td><td>True</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       " MEMNAME  MEMTYPE MEMPRSNT\n",
       " bytes40  bytes14   bool  \n",
       "--------- ------- --------\n",
       "LDIF02NMQ  EXP-FP     True\n",
       "LDIF01U0Q  EXP-FP     True\n",
       "LDIF02NUQ  EXP-FP     True\n",
       "LDIF01U4Q  EXP-FP     True\n",
       "LDIFCOMBO PROD-FP     True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(output_dir + 'ldifcombo_asn.fits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### However, the 0th and 1st fits headers no longer contain useful information about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIMPLE  =                    T / conforms to FITS standard                      \n",
       "BITPIX  =                    8 / array data type                                \n",
       "NAXIS   =                    0 / number of array dimensions                     \n",
       "EXTEND  =                    T                                                  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits.getheader(output_dir + 'ldifcombo_asn.fits', ext = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XTENSION= 'BINTABLE'           / binary table extension                         \n",
       "BITPIX  =                    8 / array data type                                \n",
       "NAXIS   =                    2 / number of array dimensions                     \n",
       "NAXIS1  =                   55 / length of dimension 1                          \n",
       "NAXIS2  =                    5 / length of dimension 2                          \n",
       "PCOUNT  =                    0 / number of group parameters                     \n",
       "GCOUNT  =                    1 / number of groups                               \n",
       "TFIELDS =                    3 / number of table fields                         \n",
       "TTYPE1  = 'MEMNAME '                                                            \n",
       "TFORM1  = '40A     '                                                            \n",
       "TTYPE2  = 'MEMTYPE '                                                            \n",
       "TFORM2  = '14A     '                                                            \n",
       "TTYPE3  = 'MEMPRSNT'                                                            \n",
       "TFORM3  = 'L       '                                                            "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits.getheader(output_dir + 'ldifcombo_asn.fits', ext = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = metaAF></a>\n",
    "## 3.1. With fits header metadata\n",
    "\n",
    "#### We can instead build up a new file with our old file's fits header, and alter it to reflect our changes.\n",
    "We first build a new association file, a Frankenstein-esque combination of our original file's headers and our new table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: data/ldif01010_asn.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      43   ()      \n",
      "  1  ASN           1 BinTableHDU     24   6R x 3C   [14A, 14A, L]   \n",
      "\n",
      "Saved: ldifcombo_2_asn.fitsin the output directory: ./output/\n"
     ]
    }
   ],
   "source": [
    "with fits.open(asnfile, mode = 'readonly') as hdulist: # Open up the old asn file\n",
    "    hdulist.info() # Shows the first hdu is empty except for the header we want\n",
    "    hdu0 = hdulist[0] # We want to directly copy over the old 0th hdu\n",
    "    d0 = hdulist[0].data # Unsure if this access should be necessary but seems to work better\n",
    "    h1 = hdulist[1].header # just copy over the old header from 1st hdu\n",
    "    \n",
    "hdu1 = fits.BinTableHDU.from_columns([c1, c2, c3], header = h1) # Put together new 1st hdu from old header and new data\n",
    "\n",
    "new_HDUlist = fits.HDUList([hdu0,hdu1]) # New HDUList from old HDU 0 and new combined HDU 1\n",
    "new_HDUlist.writeto(output_dir + 'ldifcombo_2_asn.fits', overwrite = True) # Write this out to a new file\n",
    "new_asnfile = output_dir + 'ldifcombo_2_asn.fits' # Path to this new file\n",
    "print('\\nSaved: '+ 'ldifcombo_2_asn.fits'+ f\"in the output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we edit the relevant values in our fits headers that are different from the original.\n",
    "*Note: It is possible that a generic fits file may have different values you may wish to change. It is highly recommended to examine your fits headers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editing DATE in Extension 0\n",
      "Editing FILENAME in Extension 0\n",
      "Editing ROOTNAME in Extension 0\n",
      "Editing ROOTNAME in Extension 1\n",
      "Editing ASN_ID in Extension 0\n",
      "Editing ASN_TAB in Extension 0\n",
      "Editing ASN_PROD in Extension 0\n",
      "Editing EXTVER in Extension 1\n",
      "Editing EXPNAME in Extension 1\n"
     ]
    }
   ],
   "source": [
    "date = datetime.date.today() # Grab today's date\n",
    "# Below, make a dict of what header values we want to change, corresponding to [new value , extension the value lives in, 2nd extension if applies]\n",
    "keys_to_change = {'DATE':[f'{date.year}-{date.month}-{date.day}',0], 'FILENAME':['ldifcombo_2_asn.fits',0],\n",
    "                      'ROOTNAME':['ldifcombo_2',0,1], 'ASN_ID':['ldifcombo_2',0], 'ASN_TAB':['ldifcombo_2_asn.fits',0], 'ASN_PROD':['False',0],\n",
    "                     'EXTVER':[2,1], 'EXPNAME':['ldifcombo_2',1]}\n",
    "# Actually change the values below (verbosely):\n",
    "for keyval in keys_to_change.items():\n",
    "    print(f\"Editing {keyval[0]} in Extension {keyval[1][1]}\")\n",
    "    fits.setval(filename=new_asnfile,keyword= keyval[0],value= keyval[1][0], ext = keyval[1][1])\n",
    "    # Below is necessary as some keys are repeated in both headers ('ROOTNAME')\n",
    "    if len(keyval[1])>2:\n",
    "        print(f\"Editing {keyval[0]} in Extension {keyval[1][2]}\")\n",
    "        fits.setval(filename=new_asnfile,keyword= keyval[0],value= keyval[1][0], ext = keyval[1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And there you have it - the new association file is all set and ready to be used in the `calcos` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=5</i>\n",
       "<table id=\"table140305897598200\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>MEMNAME</th><th>MEMTYPE</th><th>MEMPRSNT</th></tr></thead>\n",
       "<thead><tr><th>bytes40</th><th>bytes14</th><th>bool</th></tr></thead>\n",
       "<tr><td>LDIF02NMQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF01U0Q</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF02NUQ</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIF01U4Q</td><td>EXP-FP</td><td>True</td></tr>\n",
       "<tr><td>LDIFCOMBO</td><td>PROD-FP</td><td>True</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=5>\n",
       " MEMNAME  MEMTYPE MEMPRSNT\n",
       " bytes40  bytes14   bool  \n",
       "--------- ------- --------\n",
       "LDIF02NMQ  EXP-FP     True\n",
       "LDIF01U0Q  EXP-FP     True\n",
       "LDIF02NUQ  EXP-FP     True\n",
       "LDIF01U4Q  EXP-FP     True\n",
       "LDIFCOMBO PROD-FP     True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table.read(new_asnfile) # Re-read the table to see the change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note, however, that the file we have created has no useful information in its fits header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIMPLE  =                    T / data conform to FITS standard                  \n",
       "BITPIX  =                    8 / bits per data value                            \n",
       "NAXIS   =                    0 / number of data axes                            \n",
       "EXTEND  =                    T / File may contain standard extensions           \n",
       "NEXTEND =                    1 / Number of standard extensions                  \n",
       "GROUPS  =                    F / image is in group format                       \n",
       "DATE    = '2020-12-4'          / date this file was written (yyyy-mm-dd)        \n",
       "FILENAME= 'ldifcombo_2_asn.fits' / name of file                                 \n",
       "FILETYPE= 'ASN_TABLE'          / type of data found in data file                \n",
       "                                                                                \n",
       "TELESCOP= 'HST'                / telescope used to acquire data                 \n",
       "INSTRUME= 'COS   '             / identifier for instrument used to acquire data \n",
       "EQUINOX =               2000.0 / equinox of celestial coord. system             \n",
       "                                                                                \n",
       "              / DATA DESCRIPTION KEYWORDS                                       \n",
       "                                                                                \n",
       "ROOTNAME= 'ldifcombo_2'        / rootname of the observation set                \n",
       "PRIMESI = 'COS   '             / instrument designated as prime                 \n",
       "                                                                                \n",
       "              / TARGET INFORMATION                                              \n",
       "                                                                                \n",
       "TARGNAME= 'PDS456                         ' / proposer's target name            \n",
       "RA_TARG =   2.620825000000E+02 / right ascension of the target (deg) (J2000)    \n",
       "DEC_TARG=  -1.426557222222E+01 / declination of the target (deg) (J2000)        \n",
       "                                                                                \n",
       "              / PROPOSAL INFORMATION                                            \n",
       "                                                                                \n",
       "PROPOSID=                15309 / PEP proposal identifier                        \n",
       "LINENUM = '01.003         '    / proposal logsheet line number                  \n",
       "PR_INV_L= 'Hamann                        ' / last name of principal investigator\n",
       "PR_INV_F= 'Fred                ' / first name of principal investigator         \n",
       "PR_INV_M= '                    ' / middle name / initial of principal investigat\n",
       "                                                                                \n",
       "              / SCIENCE INSTRUMENT CONFIGURATION                                \n",
       "                                                                                \n",
       "DETECTOR= 'FUV'                / FUV or NUV                                     \n",
       "                                                                                \n",
       "              / ASSOCIATION KEYWORDS                                            \n",
       "                                                                                \n",
       "ASN_ID  = 'ldifcombo_2'        / unique identifier assigned to association      \n",
       "ASN_TAB = 'ldifcombo_2_asn.fits' / name of the association table                \n",
       "ASN_STAT= 'COMPLETE    '       / status of association (COMPLETE/INCOMPLETE)    \n",
       "ASN_PROD= 'False   '           / product created (T/F)                          "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fits.getheader(new_asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You may wish to copy over the header from one of the original files, and tweak it to reflect that this is a combination of two association files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIMPLE  =                    T / conforms to FITS standard                      \n",
       "BITPIX  =                    8 / array data type                                \n",
       "NAXIS   =                    0 / number of array dimensions                     \n",
       "EXTEND  =                    T                                                  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_header_1_ext0 = fits.getheader(asnfiles[0], ext = 0) # First original file, extension 0\n",
    "orig_header_1_ext1 = fits.getheader(asnfiles[0], ext = 1) # extension 1\n",
    "\n",
    "hdulist = fits.open('./ldifcombo_asn.fits', mode = 'update') # We need to change things with the asnfile opened and in 'update' mode\n",
    "hdulist[0].header['BLAH'] = 'blah'\n",
    "hdulist[0].header = orig_header_1_ext0\n",
    "hdulist.flush()\n",
    "fits.getheader('./ldifcombo_asn.fits', ext = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist = fits.open(asnfiles, mode = 'update') # We need to change things with the asnfile opened and in 'update' mode\n",
    "hdulist[0].header['BLAH'] = 'blah'\n",
    "hdulist[0].header = orig_header_1_ext0\n",
    "hdulist.flush()\n",
    "fits.getheader('./ldifcombo_asn.fits', ext = 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'void440'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-ed8e9eee0987>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprim_hdu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masnfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to save to the new file with all of the original comments and history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ldifcombo_asn.fits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprim_hdu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ldifcombo_asn.fits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/utils/decorators.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, val)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mobj_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0;31m# By returning the value set the setter signals that it took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/io/fits/hdu/image.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# Set new values of bitpix, bzero, and bscale now, but wait to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# revise original values until header is updated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bitpix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTYPE2BITPIX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'void440'"
     ]
    }
   ],
   "source": [
    "prim_hdu = fits.PrimaryHDU()\n",
    "prim_hdu.header = fits.getheader(asnfiles[0], ext = 0) # to save to the new file with all of the original comments and history\n",
    "Table.read('./ldifcombo_asn.fits')\n",
    "prim_hdu.data = Table.read('./ldifcombo_asn.fits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'method' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-194-b4b1c1cc008e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# #     fits.setval('./ldifcombo_asn.fits', row, value= orig_header_1_ext0[row)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0morig_header_1_ext0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m# fits.getheader('./ldifcombo_asn.fits')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'method' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# for i, row in enumerate(orig_header_1_ext0.keys()): \n",
    "#     print(row, orig_header_1_ext0[row])\n",
    "# #     fits.setval('./ldifcombo_asn.fits', row, value= orig_header_1_ext0[row)\n",
    "\n",
    "orig_header_1_ext0.values\n",
    "# fits.getheader('./ldifcombo_asn.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'record440'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-a73eb8ef891b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./temp_hdr.fits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./ldifcombo_asn.fits'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig_header_1_ext0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/utils/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarning_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/io/fits/convenience.py\u001b[0m in \u001b[0;36mwriteto\u001b[0;34m(filename, data, header, output_verify, overwrite, checksum)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \"\"\"\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m     \u001b[0mhdu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_makehdu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhdu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_image\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPrimaryHDU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mhdu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrimaryHDU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/io/fits/convenience.py\u001b[0m in \u001b[0;36m_makehdu\u001b[0;34m(data, header)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m     \u001b[0mhdu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_BaseHDU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhdu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0m_BaseHDU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ValidHDU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;31m# The HDU type was unrecognized, possibly due to a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/io/fits/hdu/base.py\u001b[0m in \u001b[0;36m_from_data\u001b[0;34m(cls, data, header, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[1;32m    380\u001b[0m         \u001b[0mklass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_hdu_class_from_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/io/fits/hdu/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, header, do_not_scale_image_data, ignore_blank, uint, scale_back)\u001b[0m\n\u001b[1;32m    989\u001b[0m             \u001b[0mdo_not_scale_image_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_not_scale_image_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    990\u001b[0m             \u001b[0mignore_blank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_blank\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 991\u001b[0;31m             scale_back=scale_back)\n\u001b[0m\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;31m# insert the keywords EXTEND\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/io/fits/hdu/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, header, do_not_scale_image_data, uint, scale_back, ignore_blank, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;31m# and _bscale to the appropriate BITPIX for the data, and always\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;31m# sets _bzero=0 and _bscale=1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;31m# Check again for BITPIX/BSCALE/BZERO in case they changed when the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/utils/decorators.py\u001b[0m in \u001b[0;36m__set__\u001b[0;34m(self, obj, val)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0mobj_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobj_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0;31m# By returning the value set the setter signals that it took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/astroconda/lib/python3.6/site-packages/astropy/io/fits/hdu/image.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0;31m# Set new values of bitpix, bzero, and bscale now, but wait to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;31m# revise original values until header is updated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bitpix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTYPE2BITPIX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bzero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'record440'"
     ]
    }
   ],
   "source": [
    "fits.writeto('./temp_hdr.fits', data = fits.getdata('./ldifcombo_asn.fits'), header = orig_header_1_ext0, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From here, you can run the `calcos` pipeline on your new association file.\n",
    "Running `calcos` is explained in *much* more detail in our [notebook on running the pipeline](https://github.com/spacetelescope/COS-Notebooks/blob/master/Calcos/Calcos.ipynb)\n",
    "\n",
    "The next two cells are only fully relavent if all of the following is true:\n",
    "1. You are not on the Space Telescope Science Institute (STScI) internet, or connected to STScI via VPN.\n",
    "2. You have not yet run the notebooks hosted in this repository on the `Calcos` pipeline *nor* the `DayNight` separation.\n",
    "\n",
    "In short, to run the `calcos` pipeline, you will need the relavent reference files. These will need be hosted in the directory assigned the environmetn variable `lref`. No matter *where* you place these files, you *must* create the lref environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "\n",
    "# set the environment variable\n",
    "%env lref ./data/reference/references/hst/cos/\n",
    "\n",
    "# IFF you haven't downloaded the referenece files, you will need the following to set up and download these files: \n",
    "%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n",
    "%env CRDS_PATH ./data/reference/\n",
    "# The next line depends on your context and pmap file \n",
    "!crds bestrefs --files data/*raw*.fits  --sync-references=2 --update-bestrefs --new-context 'hst_0836.pmap'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir+'crds_output_1.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "calcos.calcos(asnfile, verbosity=0, outdir=output_dir+\"/calcos_processed_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir+'output_calcos_1.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If we wish to determine what source we're looking at - in this case, because we don't understand the naming scheme used by the proposer who referred to this target as \"KAZ238\" - we can grab the coordinates from the fits header, and run a Simbad search for them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simbad_name(fitsfile):\n",
    "    from astroquery.simbad import Simbad\n",
    "    import astropy.coordinates as coord\n",
    "    import astropy.units as u\n",
    "    hdr = fits.getheader(fitsfile)\n",
    "    print(\"The proposer gave the TARGNAME = \", hdr['TARGNAME'], \"\\nQuerying Simbad with the coordinates:\")\n",
    "    ra,dec = hdr['RA_TARG'] ,hdr['DEC_TARG']\n",
    "    return Simbad.query_region(coord.SkyCoord(ra, dec, unit=(u.deg, u.deg)))[0]\n",
    "\n",
    "get_simbad_name(asnfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_simbad_name(asnfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below gathers some data on the same source from another association (`LCXV10070`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Observations.get_product_list(Observations.query_criteria(obs_id = 'lcxv10070*'))\n",
    "arr = []\n",
    "[arr.append(i) for i, psg in enumerate(pl['productSubGroupDescription']) if psg in ['RAWTAG_A', 'RAWTAG_B']]\n",
    "\n",
    "Observations.download_products(pl[arr][0:2], download_dir = './data/')\n",
    "\n",
    "for gfile in glob.glob(\"**/lcxv*/*.fits\", recursive=True):\n",
    "    os.rename(gfile,data_dir + os.path.basename(gfile))\n",
    "shutil.rmtree(data_dir + 'mastDownload')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl6 = Observations.get_product_list(Observations.query_criteria(obs_id = 'lcxv10060*'))\n",
    "pl7 = Observations.get_product_list(Observations.query_criteria(obs_id = 'lcxv10070*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rf in glob.glob(data_dir + '*rawtag_a*'):\n",
    "    print(fits.getheader(rf, ext = 1)['EXPSTART'])\n",
    "    print(fits.getheader(rf, ext = 0)['OPT_ELEM'])\n",
    "    print(fits.getheader(rf, ext = 0)['ASN_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBS2005\n",
    "# lcxv*\n",
    "pl = Observations.get_product_list(Observations.query_criteria(obs_id = 'lcxv*', target_name = 'RBS2055'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.download_products(pl[pl['productSubGroupDescription'] == 'RAWTAG_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = []\n",
    "arr2 = []\n",
    "arr3 = []\n",
    "for rbsfile in glob.glob(\"mas*/**/*lcxv1*fits\", recursive = True):\n",
    "    print(rbsfile, fits.getheader(rbsfile, ext = 0)['CENWAVE'])\n",
    "    if fits.getheader(rbsfile, ext = 0)['CENWAVE'] == 1291:\n",
    "        arr1.append(fits.getheader(rbsfile, ext = 1)['EXPSTART'])\n",
    "        arr2.append(fits.getheader(rbsfile, ext = 1)['EXPEND'])\n",
    "        arr3.append(fits.getheader(rbsfile, ext = 0)['ASN_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ls, le in zip(arr1,arr2):\n",
    "    plt.axvspan(ls, le)\n",
    "    plt.xlim(57298.82,57298.9)\n",
    "    plt.xticks(rotation = 'vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "pl = Observations.get_product_list(Observations.query_criteria(obs_id = 'LDIF02*'))\n",
    "for i, psgd in enumerate(pl['productSubGroupDescription']):\n",
    "    if psgd == \"RAWACQ\":\n",
    "        arr.append(i)\n",
    "Observations.download_products(pl[arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.glob('./data/*raw*fits'):\n",
    "    print(\"####### \", f)\n",
    "    print(fits.getheader(f, ext = 0)[139:150])\n",
    "    print(\"#######\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Association LDIF01010 has data/ldif01u0q_rawtag_a.fits with exptime 1404.0 seconds at cenwave 1280 Å and FP-POS 2..\n",
      "Association LDIF01010 has data/ldif01u2q_rawtag_a.fits with exptime 1404.0 seconds at cenwave 1280 Å and FP-POS 3..\n",
      "Association LDIF02010 has data/ldif02nmq_rawtag_a.fits with exptime 1653.0 seconds at cenwave 1280 Å and FP-POS 1..\n",
      "Association LDIF01010 has data/ldif01u4q_rawtag_a.fits with exptime 2923.0 seconds at cenwave 1280 Å and FP-POS 4..\n",
      "Association LDIF01010 has data/ldif01tyq_rawtag_a.fits with exptime 0.0 seconds at cenwave 1280 Å and FP-POS 1..\n",
      "Association LDIF02010 has data/ldif02nwq_rawtag_a.fits with exptime 2783.0 seconds at cenwave 1280 Å and FP-POS 4..\n",
      "Association LDIF02010 has data/ldif02nsq_rawtag_a.fits with exptime 1334.0 seconds at cenwave 1280 Å and FP-POS 2..\n",
      "Association LDIF02010 has data/ldif02nuq_rawtag_a.fits with exptime 1334.0 seconds at cenwave 1280 Å and FP-POS 3..\n"
     ]
    }
   ],
   "source": [
    "for rt_a in glob.glob(f\"**/*ldif*rawtag_a*\", recursive=True):\n",
    "        print(f\"Association {(fits.getheader(rt_a))['ASN_ID']} has {rt_a} with\\\n",
    " exptime {(fits.getheader(rt_a, ext = 1))['EXPTIME']} seconds at cenwave {(fits.getheader(rt_a, ext = 0))['CENWAVE']} Å and FP-POS {(fits.getheader(rt_a, ext = 0))['FPPOS']}..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(f\"**/*ldif*rawtag_a*\", recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ldif02nwq\".upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rt_a in glob.glob(f\"**/*ldif*rawtag_a*\", recursive=True):\n",
    "    print(rt_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
