{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "congressional-category",
   "metadata": {},
   "source": [
    "<a id=\"topL\"></a>\n",
    "\n",
    "# Working with the COS Line Spread Function\n",
    "\n",
    "# Learning Goals\n",
    "### This Notebook is designed to walk the user (*you*) through: **Altering the extraction box used to extract your spectrum from a COS `TIME-TAG` exposure file.**\n",
    "   #### 1. [**Investigating the exposure**](#invE)\n",
    "   ##### - 1.1. [Getting the first glimpse of a 2D spectrum](#lookE)\n",
    "   ##### - 1.2. [Defining some useful functions](#funE)\n",
    "   ##### - 1.3. [Examining the extraction boxes](#boxE)\n",
    "\n",
    "#### 2. [**Editing the extraction boxes**](#editE)\n",
    "   ##### - 2.1. [Defining an editing function](#edfnE)\n",
    "   ##### - 2.2. [Make the edits](#mkedE)\n",
    "   ##### - 2.3. [Confirming the changes](#confE)\n",
    "  \n",
    "#### 3. [**Running the CalCOS Pipeline with the new XTRACTAB**](#calexE)\n",
    "   ##### - 3.1. [Edit the XTRACTAB header value](#edhdrE)\n",
    "   ##### - 3.2. [Run the pipeline](#runcE)\n",
    "\n",
    "#### 4. [**Example using FUV Data**](#fuvE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-equality",
   "metadata": {},
   "source": [
    "\n",
    "# 0. Introduction\n",
    "#### The Cosmic Origins Spectrograph ([*COS*](https://www.nasa.gov/content/hubble-space-telescope-cosmic-origins-spectrograph)) is an ultraviolet spectrograph on-board the Hubble Space Telescope([*HST*](https://www.stsci.edu/hst/about)) with capabilities in the near ultraviolet (*NUV*) and far ultraviolet (*FUV*).\n",
    "\n",
    "#### This tutorial aims to prepare you to work with the COS data of your choice by walking you through altering the extraction box sizes in the XTRACTAB/`_1dx` file to make sure you are extracting the cleanest possible signal from your source and background.\n",
    "\n",
    "- For an in-depth manual to working with COS data and a discussion of caveats and user tips, see the [COS Data Handbook](https://hst-docs.stsci.edu/display/COSDHB/).\n",
    "- For a detailed overview of the COS instrument, see the [COS Instrument Handbook](https://hst-docs.stsci.edu/display/COSIHB/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-twelve",
   "metadata": {},
   "source": [
    "## We will import the following packages:\n",
    "\n",
    "- `numpy` to handle arrays and functions\n",
    "- `astropy.io fits` and `astropy.table Table` for accessing FITS files\n",
    "- `glob`, `os`, and `shutil` for working with system files\n",
    "- `astroquery.mast Observations` for finding and downloading data from the [MAST](https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html) archive\n",
    "- `matplotlib.pyplot` for plotting\n",
    "- `glob`, `os`, and `shutil` for file manipulation\n",
    "- `calcos` to run the CalCOS pipeline for COS data reduction\n",
    "- `scipy.interpolate interp1d` for interpolating datasets to the same sampling\n",
    "\n",
    "These python packages are installed standard with the the STScI conda distribution. For more information, see our notebook tutorial on [setting up an environment](https://github.com/spacetelescope/COS-Notebooks/blob/master/Setup/Setup.ipynb).\n",
    "\n",
    "We'll also filter out an unhelpful warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for array manipulation\n",
    "import numpy as np\n",
    "# for reading fits files\n",
    "from astropy.table import Table\n",
    "from astropy.io import fits\n",
    "# For downloading the data\n",
    "from astroquery.mast import Observations as Obs\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "# For dealing with system files\n",
    "import glob, os, shutil\n",
    "# For running the CalCOS pipeline\n",
    "import calcos\n",
    "# For comparing the old and new CalCOS values\n",
    "from scipy.interpolate import interp1d \n",
    "# We will also suppress a warning that won't affect our data processing:\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-model",
   "metadata": {},
   "source": [
    "## We will also define a few directories we will need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be important directories for the notebook\n",
    "datadir = './data/'\n",
    "outputdir = './output/'\n",
    "plotsdir = './output/plots/'\n",
    "\n",
    "# Make the directories in case they don't exist\n",
    "!mkdir ./output\n",
    "!mkdir ./output/plots\n",
    "!mkdir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-spray",
   "metadata": {},
   "source": [
    "## And we will need to download the data we wish to work with:\n",
    "We choose the exposures with the association obs_id: `LE4B04010` and download all the `_rawtag` data.\n",
    "For more information on downloading COS data, see our [notebook tutorial on downloading COS data](https://github.com/spacetelescope/COS-Notebooks/blob/master/DataDL/DataDl.ipynb).\n",
    "##### Note, we're working with the `_rawtags` because they are smaller files and quicker to download than the `_corrtag` files. However, this workflow translates very well to using `_corrtag` files, as you likely will want to do when working with your actual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Obs.get_product_list(Obs.query_criteria(obs_id='LE4B04010'))\n",
    "masked_pl = pl[np.isin(pl['productSubGroupDescription'],['RAWTAG', 'ASN', 'X1DSUM'])]\n",
    "# Now download:\n",
    "Obs.download_products(masked_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suitable-brazil",
   "metadata": {},
   "source": [
    "We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtags = glob.glob('./mastDownload/HST/**/*_rawtag.fits', \n",
    "                    recursive=True)\n",
    "asnfile = glob.glob('./mastDownload/HST/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/**/*_x1dsum.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-stack",
   "metadata": {},
   "source": [
    "<a id = invE></a>\n",
    "# 1. Investigating the exposure\n",
    "\n",
    "<a id = lookE></a>\n",
    "## 1.1 Getting the first glimpse of a 2D spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "union-popularity",
   "metadata": {},
   "source": [
    "### We need to see where the NUV stripes fall in order to determine where we should place the extraction boxes.\n",
    "#### We'll first plot this as a 2D image of the raw counts.\n",
    "We grab and plot the raw counts data from the 0th rawtag file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the first rawtag\n",
    "rawtag = rawtags[0]\n",
    "rtd = Table.read(rawtag,1)\n",
    "###\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "for j in [187,285,415]: # Lines roughly centered on the 3 NUV stripes\n",
    "    plt.axhline(j, color = 'm', linewidth = 3, alpha = 0.8, linestyle = 'dotted')\n",
    "\n",
    "plt.xlim(0,1024)\n",
    "plt.ylim(0,1024)\n",
    "\n",
    "plt.xlabel('Dispersion axis Pixel', size = 20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.title(\"Fig 1.1\\n2D spectrum of all raw (unfiltered) counts\", size = 25)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-suggestion",
   "metadata": {},
   "source": [
    "### Now we'll need to see where the original `XTRACTAB` places its extraction boxes:\n",
    "Find the name of the `XTRACTAB` used by this first `_rawtag` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_xtractab = fits.getheader(rawtag)['XTRACTAB']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solar-shannon",
   "metadata": {},
   "source": [
    "### If you have an existing `lref` directory with a cache of reference files:\n",
    "Give the system the `lref` system variable, which points to the reference file directory, uncomment the cell below (beginning with \"`#### YES lref?`\"), and comment out the following code cell (beginning with \"`#### NO lref?`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-reputation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YES lref?\n",
    "\n",
    "# lref = '/path/to/your/lref/'\n",
    "# %env lref /path/to/your/lref/\n",
    "# orig_xtractab = lref + orig_xtractab.split('$')[1] # This is the full path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "white-brook",
   "metadata": {},
   "source": [
    "### If you don't have an existing `lref` directory with a cache of reference files:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-wheat",
   "metadata": {},
   "source": [
    "If you do not have a local copy of the reference files, (i.e. an lref directory,) you may, for the purposes of this notebook, download just the `XTRACTAB` using the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NO lref?\n",
    "\n",
    "%env CRDS_PATH ./data\n",
    "%env CRDS_SERVER_URL https://hst-crds.stsci.edu\n",
    "%env lref ./data/references/hst/cos/\n",
    "lref = './data/references/hst/cos/'\n",
    "! crds sync --files=w5g1439sl_1dx.fits\n",
    "\n",
    "orig_xtractab = lref + orig_xtractab.split('$')[1] # This is the full path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opened-asian",
   "metadata": {},
   "source": [
    "\n",
    "<a id = funE></a>\n",
    "## 1.2 Defining some useful functions\n",
    "\n",
    "We'll define a few functions to:\n",
    "- Read in the data rows containing relevant extraction boxes from an XTRACTAB file\n",
    "- Plot these extraction boxes over a spectrum \n",
    "  + *for clarity and signal to noise, we'll collapse this spectrum onto the y (cross-dispersion) axis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-comparative",
   "metadata": {},
   "source": [
    "### First, we'll write a function to read in the relavent extraction boxes from an XTRACTAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-bradley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readxtractab(xtractab, grat, cw, aper):\n",
    "\n",
    "    \"\"\"\n",
    "    Reads in an XTRACTAB row of a particular COS mode and\\\n",
    "    gets extraction box sizes and locations.\n",
    "    Inputs:\n",
    "    xtractab (str) : path to xtractab file.\n",
    "    raw (bool) : default False, meaning that the data is assumed to be corrtag.\n",
    "    grat (string) : grating of relavent row (i.e. \"G185M\")\n",
    "    cw (int or numerical) : cenwave of relavent row (i.e. (1786))\n",
    "    aper (str) : aperture of relavent row (i.e. \"PSA\")\n",
    "    Returns:\n",
    "    y locations of bottoms/tops of extraction boxes\n",
    "        if NUV: stripe NUVA/B/C, and 2 background boxes\n",
    "        elif FUV: FUVA/B, and 2 background boxes for each FUVA/B.\n",
    "    \"\"\"\n",
    "    with fits.open(xtractab) as f:\n",
    "        xtrdata = f[1].data # Get the fits data\n",
    "    \n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    if not isFUV: # Then NUV data:\n",
    "        sel_nuva = np.where((xtrdata['segment'] == 'NUVA') & # Find NUVA \n",
    "                            (xtrdata['aperture'] == aper) & # of the right row\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') & # Now NUVB\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') & # Now NUVC\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        hgta = xtrdata['HEIGHT'][sel_nuva][0] # get heights\n",
    "        hgtb = xtrdata['HEIGHT'][sel_nuvb][0] #  of spec extract boxes\n",
    "        hgtc = xtrdata['HEIGHT'][sel_nuvc][0]\n",
    "\n",
    "        bspeca = xtrdata['B_SPEC'][sel_nuva][0] # y-intercept (b) of spec \n",
    "        bspecb = xtrdata['B_SPEC'][sel_nuvb][0] #  boxes\n",
    "        bspecc = xtrdata['B_SPEC'][sel_nuvc][0]\n",
    "\n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] # determine y bounds of boxes \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "        boundsc = [bspecc - hgtc/2, bspecc + hgtc/2]\n",
    "\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_nuva] # Do the same for the bkg extract boxes\n",
    "        bkg2a = xtrdata['B_BKG2'][sel_nuva]\n",
    "        bhgta = xtrdata['BHEIGHT'][sel_nuva]\n",
    "        bkg1boundsa = [bkg1a - bhgta/2, bkg1a + bhgta/2]\n",
    "        bkg2boundsa = [bkg2a - bhgta/2, bkg2a + bhgta/2]\n",
    "\n",
    "        # the background locations are by default the same for all stripes\n",
    "\n",
    "        return boundsa, boundsb, boundsc, bkg1boundsa, bkg2boundsa\n",
    "    \n",
    "    elif isFUV: # Then FUV data:\n",
    "        sel_fuva = np.where((xtrdata['segment'] == 'FUVA') & # Find NUVA \n",
    "                            (xtrdata['aperture'] == aper) & # of the right row\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "\n",
    "        sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') & # Now NUVB\n",
    "                            (xtrdata['aperture'] == aper) &\n",
    "                            (xtrdata['opt_elem'] == grat) &\n",
    "                            (xtrdata['cenwave'] == cw))\n",
    "        hgta = xtrdata['HEIGHT'][sel_fuva][0] # get heights\n",
    "        hgtb = xtrdata['HEIGHT'][sel_fuvb][0] #  of spec extract boxes\n",
    "        bspeca = xtrdata['B_SPEC'][sel_fuva][0] # y-intercept (b) of spec \n",
    "        bspecb = xtrdata['B_SPEC'][sel_fuvb][0] #  boxes\n",
    "        boundsa = [bspeca - hgta/2, bspeca + hgta/2] # determine y bounds of boxes \n",
    "        boundsb = [bspecb - hgtb/2, bspecb + hgtb/2]\n",
    "\n",
    "        bkg1a = xtrdata['B_BKG1'][sel_fuva] # Do the same for the bkg extract boxes\n",
    "        bkg2a = xtrdata['B_BKG2'][sel_fuva]\n",
    "        bhgt1a = xtrdata['B_HGT1'][sel_fuva]\n",
    "        bhgt2a = xtrdata['B_HGT2'][sel_fuva]\n",
    "        bkg1boundsa = [bkg1a - bhgt1a/2, bkg1a + bhgt1a/2]\n",
    "        bkg2boundsa = [bkg2a - bhgt2a/2, bkg2a + bhgt2a/2]\n",
    "        \n",
    "        bkg1b = xtrdata['B_BKG1'][sel_fuvb] # Do the same for the bkg extract boxes\n",
    "        bkg2b = xtrdata['B_BKG2'][sel_fuvb]\n",
    "        bhgt1b = xtrdata['B_HGT1'][sel_fuvb]\n",
    "        bhgt2b = xtrdata['B_HGT2'][sel_fuvb]\n",
    "        bkg1boundsb = [bkg1b - bhgt1b/2, bkg1b + bhgt1b/2]\n",
    "        bkg2boundsb = [bkg2b - bhgt2b/2, bkg2b + bhgt2b/2]\n",
    "\n",
    "        return boundsa, boundsb, bkg1boundsa, bkg2boundsa, bkg1boundsb, bkg2boundsb\n",
    "# We'll note the returned values correspond to these extraction boxes\n",
    "box_names = ['NUVA','NUVB','NUVC','BKG-1','BKG-2']\n",
    "box_names_fuv = ['FUVA','FUVB','BKG-1A','BKG-2A','BKG-1B','BKG-2B']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-browser",
   "metadata": {},
   "source": [
    "### We'll now need two functions in order to plot\n",
    "The first function (`makeims()`) is a helper function for the second: `collapsey()`.\n",
    "\n",
    "`collapsey()` takes a list of either `_rawtag` or `_corrtag` exposure files, as well as an `XTRACTAB` file, and creates a summary plot, with the 2D spectrum collapsed onto the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeims(xarr, yarr):\n",
    "    \"\"\"\n",
    "    Helper function for collapsey(): converts counts to image.\n",
    "    \"\"\"\n",
    "    new_img = np.zeros((1024, 1024))\n",
    "    xbin = np.asarray(np.floor((xarr + 0.5)), dtype=np.int)\n",
    "    ybin = np.asarray(np.floor((yarr + 0.5)), dtype=np.int)\n",
    "    # Add a count for each x,y pair\n",
    "    for x, y in zip(xbin, ybin):\n",
    "        try:\n",
    "            new_img[y, x] += 1\n",
    "        except IndexError:\n",
    "            continue\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-teach",
   "metadata": {},
   "source": [
    "### Collapse in y axis function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blond-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapsey(tagfiles, xtractab, raw = False, save = True, savename = False, fignum = False): # assumes corrtag, but will work with rawtag if raw=True\n",
    "    \"\"\"\n",
    "    Takes a corrtag (default) or rawtag and makes a plot of the 2D spectrum collapsed to the y axis\\\n",
    "    i.e. summed over rows of pixels in the dispersion direction\\\n",
    "    then it overplots the extraction regions from a provided xtractab.\n",
    "    \n",
    "    Inputs:\n",
    "    tagfiles (list of str) : list of rawtag or corrtag file paths.\n",
    "    xtractab (str) : path to xtractab.\n",
    "    raw (bool) : default False, meaning that the data is assumed to be corrtag.\n",
    "    save (bool) : Do you want to save the image of the plot? Default True\n",
    "    savename (str if specified) : name to save file as in plotsdir, if save == True.\n",
    "    fignum  (str if specified) : Figure number to include in figtitle. Dafault is False.\n",
    "    \n",
    "    Outputs:\n",
    "    yprof (numpy array of floats) : the 2D spectrum collapsed onto the y axis.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    for numfile, myfile in enumerate(tagfiles): # go through all the tag files\n",
    "\n",
    "        with fits.open(myfile) as f: # Grab data from file\n",
    "            data = f[1].data\n",
    "            h0 = f[0].header\n",
    "\n",
    "        fppos = h0['FPPOS'] # get important header keys to determin row\n",
    "        rootname = h0['ROOTNAME']\n",
    "        target = h0['TARGNAME']\n",
    "        grating = h0['OPT_ELEM']\n",
    "        cenwave = h0['CENWAVE']\n",
    "        \n",
    "        if not raw: # grab corrected or raw time-tag points x and y locations\n",
    "            xcorr = data['XCORR']\n",
    "            ycorr = data['YCORR']\n",
    "\n",
    "        elif raw:\n",
    "            rawx = data['RAWX']\n",
    "            rawy = data['RAWY']\n",
    "            \n",
    "        if raw: # call helper function on time tag data\n",
    "            nuvim = makeims(rawx, rawy)\n",
    "        else:\n",
    "            nuvim = makeims(xcorr, ycorr)\n",
    "\n",
    "        yprof = np.sum(nuvim, axis=1) # collapse onto the y axis\n",
    "\n",
    "        # Make the main y-axis spectrum plot\n",
    "        yaxis = np.arange(0, 1024)\n",
    "        plt.plot(yprof, yaxis, label=f'{rootname} fppos = {fppos}')\n",
    "        if numfile == 0: # Add in the plot formatting (just once - on the 0th file)\n",
    "            if raw:\n",
    "                plt.ylabel('RAWY Pixel', size = 18)\n",
    "            else:\n",
    "                plt.ylabel('YCORR Pixel', size = 18)\n",
    "\n",
    "            plt.xlabel('Counts summed along X', size = 18)\n",
    "            fig_title = f\"Target: {target} spectrum;\" +\"\\n\"+f\"XTRACTAB: {os.path.basename(xtractab)}\"\n",
    "            if fignum:\n",
    "                fig_title = f\"Fig {fignum}\" + \"\\n\" + fig_title\n",
    "            plt.title(fig_title, fontsize = 23)\n",
    "            psaboundsa, psaboundsb, psaboundsc, psabkg1, psabkg2 = readxtractab(xtractab, grating, cenwave, 'PSA')\n",
    "            wcaboundsa, wcaboundsb, wcaboundsc, wcabkg1, wcabkg2 = readxtractab(xtractab, grating, cenwave, 'WCA')\n",
    "\n",
    "            span = plt.axhspan(psaboundsa[0], psaboundsa[1], color='lightgray', label = 'PSA regions', alpha=0.7)\n",
    "            plt.axhspan(psaboundsb[0], psaboundsb[1], color='lightgray', alpha=0.7)\n",
    "            plt.axhspan(psaboundsc[0], psaboundsc[1], color='lightgray', alpha=0.7)\n",
    "\n",
    "            span = plt.axhspan(psabkg1[0], psabkg1[1], color='lightblue', label = 'Background regions' , alpha=0.7)\n",
    "            plt.axhspan(psabkg2[0], psabkg2[1], color='lightblue', alpha=0.7)\n",
    "            span = plt.axhspan(wcaboundsa[0], wcaboundsa[1], color='lightgreen', label = 'WCA regions', alpha=0.7)\n",
    "            plt.axhspan(wcaboundsb[0], wcaboundsb[1], color='lightgreen', alpha=0.7)\n",
    "            plt.axhspan(wcaboundsc[0], wcaboundsc[1], color='lightgreen', alpha=0.7)\n",
    "    \n",
    "    plt.legend(loc = 'upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    ### Saving the figure:\n",
    "    if save: # Do we want to save the image at all?\n",
    "        if not savename: # Save in the default manner\n",
    "            plt.savefig(plotsdir+f\"{target}_regions.png\", dpi = 200, bbox_inches = 'tight')\n",
    "        elif savename: # Save with input savename\n",
    "            plt.savefig(plotsdir+f\"{savename}.png\", dpi = 200, bbox_inches = 'tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    return yprof"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appropriate-patient",
   "metadata": {},
   "source": [
    "<a id = boxE></a>\n",
    "## 1.3. Examining the extraction boxes\n",
    "### Now let's make a plot showing where these original `XTRACTAB` boxes fall on the raw count image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_bounds = readxtractab(orig_xtractab, # bounds of all boxes...\n",
    "                           grat='G185M', cw=1786, aper='PSA') # ...for these conditions\n",
    "\n",
    "plt.figure(figsize=(10,8)) # Set up figure\n",
    "\n",
    "plt.scatter(rtd['RAWX'],rtd['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0')\n",
    "\n",
    "for i, (box, bname) in enumerate(zip(read_bounds, box_names)): # add all the boxes\n",
    "    plt.axhspan(box[0],box[1], color = 'cmykr'[i], alpha = 0.3 , label = bname)\n",
    "\n",
    "plt.legend(loc = 'upper right') # Add plot formatting\n",
    "plt.xlim(0,1024)\n",
    "plt.ylim(0,1024)\n",
    "plt.xlabel('Dispersion axis Pixel', size = 20)\n",
    "plt.ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.suptitle(\"Fig 1.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes\", size = 25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotsdir+'/2D_spec_orig_boxes.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-cedar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles = rawtags, xtractab = orig_xtractab, raw = True,\n",
    "                      save = True, savename = \"orig_xtractab_col_y\", fignum = \"1.3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-brisbane",
   "metadata": {},
   "source": [
    "<a id = editE></a>\n",
    "# 2. Editing the extraction boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-quebec",
   "metadata": {},
   "source": [
    "#### Now that we know how to show the location of the extraction boxes, we can get to the actual editing.\n",
    "##### We'll define another function to edit the existing XTRACTAB and save to a new file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-leonard",
   "metadata": {},
   "source": [
    "<a id = edfnE></a>\n",
    "## 2.1. Defining an editing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_xtractab(xtractab, gratlist, cwlist, h_dict, b_dict, new_filename):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to actually edit the XTRACTAB itself\\\n",
    "    Change the height and y-intercepts of the extraction boxes,\\\n",
    "    and save to new XTRACTAB (1dx) file.\n",
    "    Inputs:\n",
    "    xtractab (str) : path to the XTRACTAB to edit\n",
    "    gratlist (list of str) : all the gratings whose rows you would like to edit\n",
    "    cwlist (list of str) : all the cenwave whose rows you would like to edit\n",
    "    h_dict (dict of numerical) : heights of NUV A,B,C extraction boxes\n",
    "    b_dict (dict) : dict of the y-intercepts - i.e. box center locations\n",
    "    new_filename : filename/local path to new XTRACTAB file to create\n",
    "    \"\"\"\n",
    "    \n",
    "    f = fits.open(xtractab)\n",
    "\n",
    "    xtrdata = f[1].data\n",
    "    isFUV = fits.getheader(xtractab)['DETECTOR'] == 'FUV'\n",
    "    \n",
    "    for grat in gratlist:\n",
    "\n",
    "        for cw in cwlist:\n",
    "            if not isFUV: # Then NUV data:\n",
    "\n",
    "                sel_nuva = np.where((xtrdata['segment'] == 'NUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvb = np.where((xtrdata['segment'] == 'NUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_nuvc = np.where((xtrdata['segment'] == 'NUVC') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                # change the background region locations:\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuva] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuva] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvb] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvb] = b_dict['bbkg2']\n",
    "\n",
    "                xtrdata['B_BKG1'][sel_nuvc] = b_dict['bbkg1']\n",
    "                xtrdata['B_BKG2'][sel_nuvc] = b_dict['bbkg2']\n",
    "\n",
    "                # change the extraction heights\n",
    "\n",
    "                xtrdata['HEIGHT'][sel_nuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_nuvb] = h_dict['h_b']\n",
    "                xtrdata['HEIGHT'][sel_nuvc] = h_dict['h_c']\n",
    "\n",
    "                # change the B_SPEC\n",
    "\n",
    "                xtrdata['B_SPEC'][sel_nuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_nuvb] = b_dict['bspb']\n",
    "                xtrdata['B_SPEC'][sel_nuvc] = b_dict['bspc']\n",
    "                \n",
    "                \n",
    "            elif isFUV: # Then FUV data:\n",
    "                sel_fuva = np.where((xtrdata['segment'] == 'FUVA') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "\n",
    "                sel_fuvb = np.where((xtrdata['segment'] == 'FUVB') &\n",
    "                                    (xtrdata['aperture'] == 'PSA') &\n",
    "                                    (xtrdata['opt_elem'] == grat) &\n",
    "                                    (xtrdata['cenwave'] == cw))\n",
    "                # change the background region locations:\n",
    "                xtrdata['B_BKG1'][sel_fuva] = b_dict['bbkg1a']\n",
    "                xtrdata['B_BKG2'][sel_fuva] = b_dict['bbkg2a']\n",
    "                #\n",
    "                xtrdata['B_BKG1'][sel_fuvb] = b_dict['bbkg1b']\n",
    "                xtrdata['B_BKG2'][sel_fuvb] = b_dict['bbkg2b']\n",
    "                # change the extraction heights\n",
    "                xtrdata['HEIGHT'][sel_fuva] = h_dict['h_a']\n",
    "                xtrdata['HEIGHT'][sel_fuvb] = h_dict['h_b']\n",
    "                # change the B_SPEC\n",
    "                xtrdata['B_SPEC'][sel_fuva] = b_dict['bspa']\n",
    "                xtrdata['B_SPEC'][sel_fuvb] = b_dict['bspb']\n",
    "                \n",
    "    # save and close the file\n",
    "\n",
    "    f.writeto(new_filename, overwrite=True)\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-ghost",
   "metadata": {},
   "source": [
    "<a id = mkedE></a>\n",
    "## 2.2. Make the edits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-evans",
   "metadata": {},
   "source": [
    "### Now we'll need to actually edit the XTRACTAB file to have different sizes and locations of the extraction boxes using `edit_xtractab()`.\n",
    "\n",
    "For the purposes of this example, we'll **arbitrarily** set our y-intercepts and heights, just trying to roughly cover the NUV stripes, and show the different heights we can set the boxes to. *Note* that this function does not stop us from setting the boxes to overlap - but, dependent on your data, this may be a bad idea. The scope of this notebook is merely to explain *how* to alter the extraction boxes, not to determine the best box locations for any given dataset.\n",
    "\n",
    "#### First we'll set up the values we'll edit the box parameters to, then run the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be the values we set the box params to:\n",
    "intercept_dict = {\"bbkg1\":900., \"bbkg2\":60., # centers of the background extract regions\n",
    "                  'bspa':195., 'bspb':285., 'bspc':415.} # centers of NUV stripe extract regions\n",
    "hgt_dict = {'h_a':40, 'h_b':50, 'h_c':60}\n",
    "\n",
    "#Now edit using the edit_xtractab() function\n",
    "\n",
    "edit_xtractab(xtractab=orig_xtractab, gratlist = ['G185M'], cwlist = [1786,1817], # data and rows to edit\n",
    "              h_dict = hgt_dict, # new heights to set boxes to\n",
    "              b_dict=intercept_dict, new_filename = './edit_1dx.fits') # new y-intercepts (y axis locations) for boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-petroleum",
   "metadata": {},
   "source": [
    "<a id = confE></a>\n",
    "## 2.3. Confirming the changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-archives",
   "metadata": {},
   "source": [
    "### Now let's plot the old and new extraction boxes side-by-side to compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-slovakia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(14,8), sharey=True)\n",
    "# add raw count images\n",
    "ax0.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "ax1.scatter(rtd['RAWX'],rtd['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "\n",
    "# First deal with the original XTRACTAB\n",
    "read_bounds = readxtractab(orig_xtractab, grat='G185M', cw=1786, aper='PSA')\n",
    "for i, box in enumerate(read_bounds): #plot each box\n",
    "    ax0.axhspan(box[0],box[1], color = 'cmykr'[i], alpha = 0.3 , label = box_names[i]+'_new')\n",
    "# First deal with the newly edited XTRACTAB\n",
    "read_bounds = readxtractab('./edit_1dx.fits', grat='G185M', cw=1786, aper='PSA')\n",
    "for i, box in enumerate(read_bounds):\n",
    "    ax1.axhspan(box[0],box[1], color = 'cmykr'[i], alpha = 0.3 , hatch = 'x', label = box_names[i]+'_old')\n",
    "\n",
    "    # Now some plot formatting\n",
    "ax0.legend(loc = 'upper right')\n",
    "ax1.legend(loc = 'upper right')\n",
    "\n",
    "ax0.set_xlim(0,1024)\n",
    "ax0.set_ylim(0,1024)\n",
    "ax1.set_xlim(ax0.get_xlim())\n",
    "\n",
    "fig.text(0.42,-.01,'Dispersion axis Pixel', size = 20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.suptitle(\"Fig 2.1\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original ($left$) and new ($right$) extraction boxes\", size = 25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotsdir + '2D_spec_both_box_sets.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-mapping",
   "metadata": {},
   "source": [
    "### We'll also make a plot of the new boxes over the spectrum collapsed onto the y-axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to plot the original boxes over the y-axis spectrum\n",
    "flat_yspec = collapsey(tagfiles = rawtags, xtractab = './edit_1dx.fits', raw = True,\n",
    "                      save = True, savename = \"edit_xtractab_col_y\", fignum = \"2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "talented-bristol",
   "metadata": {},
   "source": [
    "<a id = calexE></a>\n",
    "# 3. Running the CalCOS Pipeline with the new XTRACTAB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tested-afternoon",
   "metadata": {},
   "source": [
    "<a id = edhdrE></a>\n",
    "## 3.2. Edit the XTRACTAB header value\n",
    "More detailed information on changing header parameters can be found in our [walkthrough notebook on `CalCOS`](https://github.com/spacetelescope/COS-Notebooks/blob/master/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "Here, we just need to tell the pipeline to use our newly edited XTRACTAB. We do this by editing one of the header key values in all of the affected files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    for rawtag in rawtags:\n",
    "        os.rename(rawtag, datadir + os.path.basename(rawtag))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "try: \n",
    "    os.rename(asnfile, datadir + os.path.basename(asnfile))\n",
    "except FileNotFoundError:\n",
    "    print ('No files')\n",
    "rawtags = glob.glob(datadir + '*rawtag*')\n",
    "asnfile = glob.glob(datadir + '*asn*')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-calculation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rawtag in rawtags:\n",
    "    print(\"changing XTRACTAB for \", os.path.basename(rawtag))\n",
    "    print(\"\\tOriginally: \", fits.getheader(rawtag)['XTRACTAB'])\n",
    "    fits.setval(filename=rawtag, keyword='XTRACTAB', value= './edit_1dx.fits' )\n",
    "    print(\"\\tNow set to: \", fits.getheader(rawtag)['XTRACTAB'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-cable",
   "metadata": {},
   "source": [
    "<a id = runcE></a>\n",
    "## 3.3. Run the pipeline\n",
    "We will also largely gloss over the details of running the pipeline, `CalCOS`, in this notebook. Once again, much more detailed information on running the `CalCOS` pipeline can be found in our [walkthrough notebook on `CalCOS`](https://github.com/spacetelescope/COS-Notebooks/blob/master/CalCOS/CalCOS.ipynb).\n",
    "\n",
    "*Note* you may get a \"RuntimeWarning\" when running the pipeline, but this is unlikely to be a problem. However you should certainly examine your data to make sure it seems reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment var to find all other ref files\n",
    "%env lref /grp/hst/cdbs/lref/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr \n",
    "# Above, capture the output and save it in the next cell\n",
    "\n",
    "# This line actually runs the pipeline:\n",
    "calcos.calcos(asnfile, verbosity = 1, outdir = outputdir+\"calcos_run1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(outputdir+'output_calcos_1.txt', 'w') as f: # This file now contains the output of the last cell\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-atmosphere",
   "metadata": {},
   "source": [
    "### We'll finish up by plotting the new and original `x1dsum` spectra as extracted with the new and original extraction boxes:\n",
    "*Note* that we can ignore the UnitsWarning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up figure\n",
    "fig = plt.figure(figsize = (20, 7))\n",
    "gs = fig.add_gridspec(nrows = 5, ncols = 3) # Using gridspec to let us control panel sizes and locations\n",
    "\n",
    "for i in range(3):\n",
    "    ax0 = fig.add_subplot(gs[0:4,i])\n",
    "    ax1 = fig.add_subplot(gs[4:5,i])\n",
    "    new_wvln, new_flux = Table.read('./output/calcos_run1/le4b04010_x1dsum.fits')[i]['WAVELENGTH', 'FLUX']\n",
    "    old_wvln, old_flux, seg = Table.read(old_x1dsum)[i]['WAVELENGTH', 'FLUX', 'SEGMENT']\n",
    "    \n",
    "    # Interpolate the new wvln onto the old wvln's sampling:\n",
    "    new_flux_interp = interp1d(x = new_wvln, y = new_flux, fill_value=\"extrapolate\")(old_wvln)\n",
    "\n",
    "    # give max difference:\n",
    "    print(f\"Stripe {seg} differs by up to: \\\n",
    "    {max(new_flux - old_flux)/np.mean(abs(old_flux)):.3f}%\")\n",
    "\n",
    "    # Plotting - upper panel\n",
    "    ax0.plot(new_wvln,new_flux, linewidth = .5, label = '$New$ extracted spectrum')\n",
    "    ax0.plot(old_wvln,old_flux, linewidth = .5, label = '$Original$ extracted spectrum')\n",
    "    # Plotting - lower panel\n",
    "    ax1.plot(new_wvln,old_flux - new_flux_interp, linewidth = .5, label = 'Residual')\n",
    "    # Some formatting:\n",
    "    ax0.set_title(f\"Segment {seg}\", fontsize = 20)\n",
    "    ax0.set_xticks([])\n",
    "    ax0.legend(loc = 'lower center')\n",
    "    ax1.legend(loc = 'lower center')\n",
    "    if i == 0: # Add axis labels to the plot\n",
    "        ax0.set_ylabel(\"Flux\\n[$erg\\ \\AA^{-1}\\ cm^{-2}\\ s^{-1}$]\", fontsize = 20)\n",
    "    if i == 1:\n",
    "        plt.xlabel(\"Wavelength\", fontsize = 20)\n",
    "plt.suptitle(\"Fig 3.1\\nComparing the two extracted spectra\", fontsize = 25)\n",
    "plt.tight_layout()\n",
    "plt.savefig(plotsdir+\"comp_extracted.png\", dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-seafood",
   "metadata": {},
   "source": [
    "<a id = fuvE></a>\n",
    "# 4. Example using FUV data\n",
    "\n",
    "### Let's go through doing all of the above with an FUV dataset and corresponding FUV XTRACTAB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-sacramento",
   "metadata": {},
   "source": [
    "#### First download the FUV data, we'll grab an FUV/G160M/C1533 dataset from the same proposal as the NUV dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Obs.get_product_list(Obs.query_criteria(proposal_id=15869, obs_id = 'LE4B01040'))\n",
    "masked_pl = pl[np.isin(pl['productSubGroupDescription'],['RAWTAG_A','RAWTAG_B', 'ASN', 'X1DSUM'])]\n",
    "\n",
    "# Now download:\n",
    "Obs.download_products(masked_pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "international-wilson",
   "metadata": {},
   "source": [
    "#### We gather a list of all the `_rawtag` files we have downloaded, as well as the `_asnfile` and `_x1dsum` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawtags_a = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_a.fits', \n",
    "                    recursive=True)\n",
    "rawtags_b = glob.glob('./mastDownload/HST/le4b01*/**/*_rawtag_b.fits', \n",
    "                    recursive=True)\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "asnfile = glob.glob('./mastDownload/HST/le4b01040/**/*_asn.fits', \n",
    "                    recursive=True)[0]\n",
    "old_x1dsum = glob.glob('./mastDownload/HST/le4b01040/**/*_x1dsum.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-phrase",
   "metadata": {},
   "source": [
    "#### Move the files and index them again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./fuv_data\n",
    "\n",
    "fdatadir = './fuv_data/' # Move all this FUV data, except the calibrated x1dsum, which we don't need to\n",
    "[os.rename(rta, fdatadir+ os.path.basename(rta)) for rta in rawtags_a]\n",
    "[os.rename(rtb, fdatadir+ os.path.basename(rtb)) for rtb in rawtags_b]\n",
    "os.rename(asnfile, fdatadir+ os.path.basename(asnfile))\n",
    "\n",
    "# re-find all the data now that it's moved\n",
    "rawtags_a = glob.glob('./fuv_data/*_rawtag_a.fits', \n",
    "                    recursive=True)\n",
    "rawtags_b = glob.glob('./fuv_data/*_rawtag_b.fits', \n",
    "                    recursive=True)\n",
    "rawtags_ab = rawtags_a + rawtags_b\n",
    "asnfile = glob.glob('./fuv_data/*_asn.fits', \n",
    "                    recursive=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-illinois",
   "metadata": {},
   "source": [
    "### We need to see where the FUV spectra fall in order to determine where we should place the extraction boxes.\n",
    "#### We'll first plot this as a 2D image of the raw counts.\n",
    "We grab and plot the raw counts data from the 0th `rawtag_a` and `rawtag_b` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data from the first rawtag\n",
    "rtda = Table.read(rawtags_a[0],1)\n",
    "rtdb = Table.read(rawtags_b[0],1)\n",
    "###\n",
    "\n",
    "fig, (ax0,ax1) = plt.subplots(1,2,figsize=(16,8))\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "ax1.scatter(rtda['RAWX'],rtda['RAWY'], s= 0.1, alpha = 0.1, c= 'C0')\n",
    "\n",
    "ax0.set_title(\"Segment FUVB\", fontsize = 20)\n",
    "ax1.set_title(\"Segment FUVA\", fontsize = 20)\n",
    "\n",
    "ax0.set_xlabel('Dispersion axis Pixel',size = 20)\n",
    "ax1.set_xlabel('Dispersion axis Pixel',size = 20)\n",
    "ax0.set_ylabel('Cross-dispersion axis Pixel', size = 20)\n",
    "plt.suptitle(\"Fig 4.1\\n2D spectrum of all raw (unfiltered) counts\", size = 25)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(plotsdir+'fuv_2Dspectrum.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informal-omaha",
   "metadata": {},
   "source": [
    "#### We need to get the right XTRACTAB. \n",
    "The next cell tells you what this *should* be, and you download it in the cell that follows. Make sure these filenames match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-daisy",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_fuv_1dx = fits.getheader(rawtags_a[0])['XTRACTAB'].split(\"$\")[1]\n",
    "print(\"Make sure the next line is set to download: \", correct_fuv_1dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behind-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "! crds sync --files=2bj2256il_1dx.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-hacker",
   "metadata": {},
   "source": [
    "### Now we can plot the original fuv boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuv_xtractab = f'./data/references/hst/cos/{correct_fuv_1dx}'\n",
    "read_bounds = readxtractab(fuv_xtractab, grat='G160M', cw=1533, aper = 'PSA')\n",
    "fig, (ax0,ax1) =plt.subplots(2,1, figsize=(10,8), sharex=True) # Set up figure\n",
    "\n",
    "ax1.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag A\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "\n",
    "for i, (box, bname) in enumerate(zip(read_bounds, box_names_fuv)): # add all the boxes\n",
    "    if 'A' not in bname: # FUVA in ax1 (right), FUVB in ax0 (left)\n",
    "        ax0.axhspan(box[0],box[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "    else:\n",
    "        ax1.axhspan(box[0],box[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc = 'upper right') \n",
    "ax1.legend(loc = 'upper right') \n",
    "ax0.set_xlim(920,15450)\n",
    "ax0.set_ylim(300,700)\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "ax1.set_xlabel('Dispersion axis Pixel', size = 20)\n",
    "fig.text(-0.01,0.2,'Cross-dispersion axis Pixel', size = 20, rotation = 'vertical')\n",
    "plt.suptitle(\"Fig 4.2\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original extraction boxes in the FUV\", size = 25)\n",
    "plt.tight_layout()\n",
    "# Save it\n",
    "plt.savefig(plotsdir+'/2D_spec_orig_boxes_fuv.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-priest",
   "metadata": {},
   "source": [
    "### Here we make the edits to the XTRACTAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-fifty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These will be the values we set the box params to:\n",
    "intercept_dict_fuv = {\"bbkg1a\":550., \"bbkg2a\":340.,# centers of the background extract regions\n",
    "                  \"bbkg1b\":350., \"bbkg2b\":665.,\n",
    "                  'bspa':415., 'bspb':469.} # centers of NUV stripe extract regions\n",
    "hgt_dict_fuv = {'h_a':50, 'h_b':40}\n",
    "\n",
    "#Now edit using the edit_xtractab() function\n",
    "\n",
    "edit_xtractab(xtractab=fuv_xtractab, gratlist = ['G160M'], cwlist = [1533], # data and rows to edit\n",
    "              h_dict = hgt_dict_fuv, # new heights to set boxes to\n",
    "              b_dict=intercept_dict_fuv, new_filename = './edit_fuv_1dx.fits') # new y-intercepts (y axis locations) for boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-reverse",
   "metadata": {},
   "source": [
    "### We'll finish up with a plot showing the old and new extraction boxes side-by-side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "square-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_bounds = readxtractab(fuv_xtractab, grat='G160M', cw=1533, aper = 'PSA') # original boxes\n",
    "read_bounds_fuv_edit = readxtractab('./edit_fuv_1dx.fits', grat='G160M', cw=1533, aper = 'PSA') # edited boxes\n",
    "\n",
    "     # Orig      New/Edited\n",
    "fig, ((ax0,ax1), (ax2,ax3)) = plt.subplots(2,2, figsize=(20,10), sharex=True, sharey=True) # Set up figure\n",
    "\n",
    "# The original \n",
    "ax2.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag A\n",
    "ax0.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "ax3.scatter(rtda['RAWX'],rtda['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag A\n",
    "ax1.scatter(rtdb['RAWX'],rtdb['RAWY'], # image of the raw counts\n",
    "            s= 0.1, alpha = 0.1, c= 'C0') # Rawtag B\n",
    "\n",
    "\n",
    "for i, (oldbox, newbox, bname) in enumerate(zip(read_bounds, read_bounds_fuv_edit, box_names_fuv)): # add all the boxes\n",
    "    if 'A' not in bname: # FUVA in ax0,1 (top left/right) \n",
    "        ax0.axhspan(oldbox[0],oldbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "        ax1.axhspan(newbox[0],newbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "    else: # FUVB in ax2,3 (bottom left/right)\n",
    "        ax2.axhspan(oldbox[0],oldbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "        ax3.axhspan(newbox[0],newbox[1], color = 'cmkyky'[i], hatch = '/\\+x+x'[i], alpha = 0.3 , label = bname)\n",
    "\n",
    "# Add plot formatting\n",
    "ax0.legend(loc = 'upper right') \n",
    "ax1.legend(loc = 'upper right')\n",
    "ax2.legend(loc = 'upper right') \n",
    "ax3.legend(loc = 'upper right')\n",
    "\n",
    "ax0.set_xlim(920,15450)\n",
    "ax0.set_ylim(300,700)\n",
    "ax1.set_ylim(ax0.get_ylim())\n",
    "\n",
    "ax0.set_title(\"Original extraction boxes\", fontsize = 20)\n",
    "ax1.set_title(\"Edited extraction boxes\", fontsize = 20)\n",
    "\n",
    "fig.text(-0.01,0.2,'Cross-dispersion axis Pixel', size = 20, rotation = 'vertical')\n",
    "fig.text(0.45, -0.01,'Dispersion axis Pixel', size = 20)\n",
    "\n",
    "plt.suptitle(\"Fig 4.3\\n2D spectrum of all raw (unfiltered) counts\\n\"+\\\n",
    "             \"with original and edited extraction boxes in the FUV\", size = 25)\n",
    "plt.tight_layout()\n",
    "# Save it\n",
    "plt.savefig(plotsdir+'/2D_spec_origedit_boxes_fuv.png', dpi = 200, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-table",
   "metadata": {},
   "source": [
    "## Congratulations! You finished this notebook!\n",
    "### There are more COS data walkthrough notebooks on different topics. You can find them [here](https://github.com/spacetelescope/COS-Notebooks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-liability",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## About this Notebook\n",
    "**Author:** Nat Kerman <nkerman@stsci.edu>\n",
    "\n",
    "**Contributors:** Elaine Mae Frazer\n",
    "\n",
    "**Updated On:** 2021-03-02\n",
    "\n",
    "> *This tutorial was generated to be in compliance with the [STScI style guides](https://github.com/spacetelescope/style-guides) and would like to cite the [Jupyter guide](https://github.com/spacetelescope/style-guides/blob/master/templates/example_notebook.ipynb) in particular.*\n",
    "\n",
    "## Citations\n",
    "\n",
    "If you use `astropy`, `matplotlib`, `astroquery`, or `numpy` for published research, please cite the\n",
    "authors. Follow these links for more information about citations:\n",
    "\n",
    "* [Citing `astropy`/`numpy`/`matplotlib`](https://www.scipy.org/citing.html)\n",
    "* [Citing `astroquery`](https://astroquery.readthedocs.io/en/latest/)\n",
    "\n",
    "---\n",
    "\n",
    "[Top of Page](#topL)\n",
    "<img style=\"float: right;\" src=\"https://raw.githubusercontent.com/spacetelescope/notebooks/master/assets/stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"Space Telescope Logo\" width=\"200px\"/> \n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "<br></br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
